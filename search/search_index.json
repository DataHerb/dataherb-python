{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Documentation for DataHerb \u00a4 The Python Package for DataHerb A DataHerb Core Service to Create and Load Datasets. Homebrew for datasets. dataherb is the homebrew (or snap if you are using linux) for datasets. Install \u00a4 pip install dataherb Documentation: dataherb.github.io/dataherb-python The DataHerb Command-Line Tool \u00a4 Requires Python 3 The DataHerb cli provides tools to create dataset metadata, validate metadata, search dataset in flora, and download dataset. Configure \u00a4 Before we get started, please configure dataherb first: dataherb configure Search and Download \u00a4 Search by keyword dataherb search covid19 # Shows the minimal metadata Search by dataherb id dataherb search -i covid19_eu_data # Shows the full metadata Download dataset by dataherb id dataherb download covid19_eu_data # Downloads this dataset: http://dataherb.io/flora/covid19_eu_data Create Dataset Using Command Line Tool \u00a4 We provide a template for dataset creation. Within a dataset folder where the data files are located, use the following command line tool to create the metadata template. dataherb create Upload dataset to remote \u00a4 Within the dataset folder, run dataherb upload UI for all the datasets in a flora \u00a4 dataherb serve Use DataHerb in Your Code \u00a4 Load Data into DataFrame \u00a4 # Load the package from dataherb.flora import Flora # Initialize Flora service # The Flora service holds all the dataset metadata use_flora = \"path/to/my/flora.json\" dataherb = Flora(flora=use_flora) # Search datasets with keyword(s) geo_datasets = dataherb.search(\"geo\") print(geo_datasets) # Get a specific file from a dataset and load as DataFrame tz_df = pd.read_csv( dataherb.herb( \"geonames_timezone\" ).get_resource( \"dataset/geonames_timezone.csv\" ) ) print(tz_df) The DataHerb Project \u00a4 What is DataHerb \u00a4 DataHerb is an open-source data discovery and management tool. A DataHerb or Herb is a dataset. A dataset comes with the data files, and the metadata of the data files. A Herb Resource or Resource is a data file in the DataHerb. A Flora is the combination of all the DataHerbs. In many data projects, finding the right datasets to enhance your data is one of the most time consuming part. DataHerb adds flavor to your data project. By creating metadata and manage the datasets systematically, locating an dataset is much easier. Currently, dataherb supports sync dataset between local and S3/git. Each dataset can have its own remote location. What is DataHerb Flora \u00a4 We desigined the following workflow to share and index open datasets. The repo dataherb-flora is a demo flora that lists some datasets and demonstrated on the website https://dataherb.github.io . At this moment, the whole system is being renovated. Development \u00a4 Create a conda environment. Install requirements: pip install -r requirements.txt Documentation \u00a4 The source of the documentation for this package is located at docs . References and Acknolwedgement \u00a4 dataherb uses datapackage in the core. datapackage is a python library for the data-package standard . The core schema of the dataset is essentially the data-package standard.","title":"Home"},{"location":"#documentation-for-dataherb","text":"","title":"Documentation for DataHerb"},{"location":"#install","text":"pip install dataherb Documentation: dataherb.github.io/dataherb-python","title":"Install"},{"location":"#the-dataherb-command-line-tool","text":"Requires Python 3 The DataHerb cli provides tools to create dataset metadata, validate metadata, search dataset in flora, and download dataset.","title":"The DataHerb Command-Line Tool"},{"location":"#configure","text":"Before we get started, please configure dataherb first: dataherb configure","title":"Configure"},{"location":"#search-and-download","text":"Search by keyword dataherb search covid19 # Shows the minimal metadata Search by dataherb id dataherb search -i covid19_eu_data # Shows the full metadata Download dataset by dataherb id dataherb download covid19_eu_data # Downloads this dataset: http://dataherb.io/flora/covid19_eu_data","title":"Search and Download"},{"location":"#create-dataset-using-command-line-tool","text":"We provide a template for dataset creation. Within a dataset folder where the data files are located, use the following command line tool to create the metadata template. dataherb create","title":"Create Dataset Using Command Line Tool"},{"location":"#upload-dataset-to-remote","text":"Within the dataset folder, run dataherb upload","title":"Upload dataset to remote"},{"location":"#ui-for-all-the-datasets-in-a-flora","text":"dataherb serve","title":"UI for all the datasets in a flora"},{"location":"#use-dataherb-in-your-code","text":"","title":"Use DataHerb in Your Code"},{"location":"#load-data-into-dataframe","text":"# Load the package from dataherb.flora import Flora # Initialize Flora service # The Flora service holds all the dataset metadata use_flora = \"path/to/my/flora.json\" dataherb = Flora(flora=use_flora) # Search datasets with keyword(s) geo_datasets = dataherb.search(\"geo\") print(geo_datasets) # Get a specific file from a dataset and load as DataFrame tz_df = pd.read_csv( dataherb.herb( \"geonames_timezone\" ).get_resource( \"dataset/geonames_timezone.csv\" ) ) print(tz_df)","title":"Load Data into DataFrame"},{"location":"#the-dataherb-project","text":"","title":"The DataHerb Project"},{"location":"#what-is-dataherb","text":"DataHerb is an open-source data discovery and management tool. A DataHerb or Herb is a dataset. A dataset comes with the data files, and the metadata of the data files. A Herb Resource or Resource is a data file in the DataHerb. A Flora is the combination of all the DataHerbs. In many data projects, finding the right datasets to enhance your data is one of the most time consuming part. DataHerb adds flavor to your data project. By creating metadata and manage the datasets systematically, locating an dataset is much easier. Currently, dataherb supports sync dataset between local and S3/git. Each dataset can have its own remote location.","title":"What is DataHerb"},{"location":"#what-is-dataherb-flora","text":"We desigined the following workflow to share and index open datasets. The repo dataherb-flora is a demo flora that lists some datasets and demonstrated on the website https://dataherb.github.io . At this moment, the whole system is being renovated.","title":"What is DataHerb Flora"},{"location":"#development","text":"Create a conda environment. Install requirements: pip install -r requirements.txt","title":"Development"},{"location":"#documentation","text":"The source of the documentation for this package is located at docs .","title":"Documentation"},{"location":"#references-and-acknolwedgement","text":"dataherb uses datapackage in the core. datapackage is a python library for the data-package standard . The core schema of the dataset is essentially the data-package standard.","title":"References and Acknolwedgement"},{"location":"changelog/","text":"DataHerb Changelog \u00a4 0.1.4 - 2021-08-07 \u00a4 Added: Better search result formatting in terminal Show config using dataherb configure --show Changed: Better config management 0.1.2 - 2021-08-06 \u00a4 Added dataherb configure to configure the command line too.","title":"Changelog"},{"location":"changelog/#dataherb-changelog","text":"","title":"DataHerb Changelog"},{"location":"changelog/#014-2021-08-07","text":"Added: Better search result formatting in terminal Show config using dataherb configure --show Changed: Better config management","title":"0.1.4 - 2021-08-07"},{"location":"changelog/#012-2021-08-06","text":"Added dataherb configure to configure the command line too.","title":"0.1.2 - 2021-08-06"},{"location":"references/","text":"References \u00a4 In this section, we document the key functions and classes.","title":"Introduction"},{"location":"references/#references","text":"In this section, we document the key functions and classes.","title":"References"},{"location":"references/command/","text":"Command Line Tool \u00a4 Warning Requires Python 3. The DataHerb cli tool provides some utilities to create dataset metadata, validate metadata, search dataset in flora, upload dataset to remote, and download dataset. Create Dataset \u00a4 Suppose you have some csv files in a folder called my_csv_data . Get into the folder cd my_csv_data Run dataherb create and answer a few questions. Behind the scenes, the answers to these questions will be combined with the inferred schema of the dataset by datapackage . Search and Download \u00a4 Search by keyword dataherb search covid19 # Shows the minimal metadata Search by dataherb id dataherb search -i covid19_eu_data # Shows the full metadata Download dataset by dataherb id dataherb download covid19_eu_data # Downloads this dataset: http://dataherb.io/flora/covid19_eu_data Create Dataset Using Command Line Tool \u00a4 Dataherb provides a template for dataset creation. Within a dataset folder where the data files are located, use the following command line tool to create the metadata template. dataherb create Warning It is recommended that one go though the generated dataherb.json file in the folder and make sure things like names and descriptions are correct. Sometimes human simply creates typos. Upload dataset to remote \u00a4 Within the dataset folder, run dataherb upload UI for all the datasets in a flora \u00a4 dataherb serve A website will be running and we can browse all the datasets. Dataset search is also included. Note The website is built with mkdocs. It is also very easy to deploy the generate website to any server that supports static html.","title":"Command Line Tool"},{"location":"references/command/#command-line-tool","text":"Warning Requires Python 3. The DataHerb cli tool provides some utilities to create dataset metadata, validate metadata, search dataset in flora, upload dataset to remote, and download dataset.","title":"Command Line Tool"},{"location":"references/command/#create-dataset","text":"Suppose you have some csv files in a folder called my_csv_data . Get into the folder cd my_csv_data Run dataherb create and answer a few questions. Behind the scenes, the answers to these questions will be combined with the inferred schema of the dataset by datapackage .","title":"Create Dataset"},{"location":"references/command/#search-and-download","text":"Search by keyword dataherb search covid19 # Shows the minimal metadata Search by dataherb id dataherb search -i covid19_eu_data # Shows the full metadata Download dataset by dataherb id dataherb download covid19_eu_data # Downloads this dataset: http://dataherb.io/flora/covid19_eu_data","title":"Search and Download"},{"location":"references/command/#create-dataset-using-command-line-tool","text":"Dataherb provides a template for dataset creation. Within a dataset folder where the data files are located, use the following command line tool to create the metadata template. dataherb create Warning It is recommended that one go though the generated dataherb.json file in the folder and make sure things like names and descriptions are correct. Sometimes human simply creates typos.","title":"Create Dataset Using Command Line Tool"},{"location":"references/command/#upload-dataset-to-remote","text":"Within the dataset folder, run dataherb upload","title":"Upload dataset to remote"},{"location":"references/command/#ui-for-all-the-datasets-in-a-flora","text":"dataherb serve A website will be running and we can browse all the datasets. Dataset search is also included. Note The website is built with mkdocs. It is also very easy to deploy the generate website to any server that supports static html.","title":"UI for all the datasets in a flora"},{"location":"references/flora/","text":"dataherb.flora \u00a4 Flora \u00a4 A container of datasets. It loads a local folder of dataset metadata and forms a list of dataset objects. The provided local path or remote resource will then be converted to a list of dataherb objects. Parameters: Name Type Description Default flora path to the flora database. Either an URL or a local path. required is_aggregated bool if True, the flora is aggregated into one json file. False Source code in dataherb/flora.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 class Flora : \"\"\" A container of datasets. It loads a local folder of dataset metadata and forms a list of dataset objects. The provided local path or remote resource will then be converted to a list of dataherb objects. :param flora: path to the flora database. Either an URL or a local path. :param is_aggregated: if True, the flora is aggregated into one json file. \"\"\" def __init__ ( self , flora_path : Union [ Path , URL ], is_aggregated : bool = False ): self . is_aggregated = is_aggregated if not isinstance ( flora_path , ( Path , URL )): raise Exception ( f \"flora must be a path or a url. ( { flora_path } )\" ) if isinstance ( flora_path , URL ): self . flora = self . _get_remote_flora ( flora_path ) if isinstance ( flora_path , Path ): if flora_path . suffix == \".json\" : self . is_aggregated = True self . workdir = flora_path . parent . parent self . flora_path = flora_path self . flora = self . _get_local_flora ( flora_path ) if is_aggregated != self . is_aggregated : logger . warning ( f \"flora has is_aggregated= { self . is_aggregated } , \" \"but was specified as is_aggregated= {is_aggregated} .\" ) logger . debug ( f \"flora workdir { self . workdir } \" ) def _get_local_flora ( self , flora_config : Path ) -> List [ Herb ]: \"\"\" _get_local_flora fetch flora from the local folder or file. There are two scenarios: - The flora is one aggregated local json file. - The flora is a folder that contains folders of dataset ids. \"\"\" if self . is_aggregated : with open ( flora_config , \"r\" ) as f : json_flora = json . load ( f ) else : flora_folder = Path ( flora_config ) herb_paths = [ f for f in flora_folder . iterdir () if f . is_dir ()] json_flora = [ json . load ( open ( f . joinpath ( \"dataherb.json\" ), \"r\" )) for f in herb_paths ] return [ Herb ( herb , base_path = self . workdir / f ' { herb . get ( \"id\" , \"\" ) } ' ) for herb in json_flora ] def _get_remote_flora ( self , flora_config : URL ) -> List [ Herb ]: \"\"\" _get_remote_flora fetch flora from the remote API. !!! warning Currently, this mode only works for aggregated json flora. \"\"\" flora_request = get_data_from_url ( flora_config ) if not flora_request . status_code == 200 : raise Exception ( \"Could not download dataherb flora from remote. status code: {} \" . format ( flora_request . status_code ) ) else : json_flora = flora_request . json () return [ Herb ( herb , base_path = self . workdir / f ' { herb . get ( \"id\" , \"\" ) } ' ) for herb in json_flora ] def add ( self , herb : Union [ Herb , dict , MetaData ]) -> None : \"\"\" Add a herb to the flora. \"\"\" herb = self . _convert_to_herb ( herb ) logger . debug ( f \"adding herb with metadata: { herb . metadata } \" ) for h_exist in self . flora : if herb . id == h_exist . id : raise Exception ( f \"herb id = { herb . id } already exists\" ) self . flora . append ( herb ) if self . is_aggregated : self . save ( path = self . flora_path ) else : self . save ( herb = herb ) def _convert_to_herb ( self , herb : Union [ Herb , dict , MetaData ]) -> Herb : if isinstance ( herb , MetaData ): herb = Herb ( herb . metadata ) elif isinstance ( herb , dict ): herb = Herb ( herb ) elif isinstance ( herb , Herb ): pass else : raise Exception ( f \"Input herb type ( { type ( herb ) } ) is not supported.\" ) return herb def remove ( self , herb_id : str ) -> None : \"\"\" Removes a herb from the flora. \"\"\" for id in [ i . id for i in self . flora ]: if id == herb_id : logger . debug ( f \"found herb id = { herb_id } \" ) self . flora = [ h for h in self . flora if h . id != herb_id ] if self . is_aggregated : self . save ( path = self . flora_path ) else : self . remove_herb_from_flora ( herb_id ) def save ( self , path : Optional [ Path ] = None , id : Optional [ str ] = None , herb : Optional [ Herb ] = None , ) -> None : \"\"\"save flora metadata to json file\"\"\" if path is None : path = self . flora_path logger . debug ( f \"type of a herb in flora: { type ( self . flora [ 0 ]) } \\n { self . flora [ 0 ] . metadata } \" ) if self . is_aggregated : serialized_flora = [] for h in self . flora : logger . debug ( f \"herb (type { type ( h ) } ): { h } \" ) serialized_flora . append ( h . metadata ) with open ( path , \"w\" ) as fp : json . dump ( serialized_flora , fp , sort_keys = True , indent = 4 , separators = ( \",\" , \": \" ), ) else : if ( not id ) and ( not herb ): raise Exception ( \"dataherb id must be provided\" ) elif herb : logger . debug ( f \"Saving herb using herb object\" ) self . save_herb_meta ( id = herb . id , path = path / f \" { herb . id } \" ) elif id : logger . debug ( f \"Saving herb using herb id\" ) self . save_herb_meta ( id , path / f \" { id } \" ) def save_herb_meta ( self , id : str , path : Optional [ Path ] = None ) -> None : \"\"\"Save a herb metadata to json file\"\"\" if path is None : path = self . workdir / f \" { id } \" if not path . exists (): path . mkdir ( parents = True ) logger . debug ( f \"Will replace dataherb id { id } \" ) with open ( path / \"dataherb.json\" , \"w\" ) as fp : json . dump ( self . herb_meta ( id ), fp , sort_keys = True , indent = 4 , separators = ( \",\" , \": \" ) ) def remove_herb_from_flora ( self , id : str , path : Optional [ Path ] = None ) -> None : \"\"\"Remove a herb metadata to json file\"\"\" if path is None : path = self . workdir / f \" { id } \" if not path . exists (): logger . debug ( f \"dataherb { id } doesn't exist\" ) return else : try : shutil . rmtree ( path ) except OSError as e : logger . error ( f \"Can not remove herb id { id } : { e . filename } - { e . strerror } .\" ) def search ( self , keywords : Union [ str , List [ str ]]) -> List [ dict ]: \"\"\" search finds the datasets that matches the keywords :param keywords: keywords to be searched \"\"\" if isinstance ( keywords , str ): keywords = [ keywords ] return search_by_keywords_in_flora ( flora = self . flora , keywords = keywords ) def herb_meta ( self , id : str ) -> Optional [ dict ]: \"\"\" herb loads the dataset :param id: herb id of the dataset \"\"\" herbs = _search_by_ids_in_flora ( self . flora , id ) if herbs : herb = herbs [ 0 ] . get ( \"herb\" ) if herb : return herb . metadata else : return None else : return None def herb ( self , id : str ) -> Optional [ Herb ]: \"\"\" herb loads the dataset as dataframes. :param id: herb id \"\"\" herbs = _search_by_ids_in_flora ( self . flora , id ) if len ( herbs ) > 1 : logger . error ( f \"Found multiple datasets with id { id } , please fix this in your flora data json file, e.g, WORKDIRECTORY/flora/flora.json.\" ) if herbs : herb = herbs [ 0 ] . get ( \"herb\" ) if herb : return herb else : return None else : logger . error ( f \"Could not find herb { id } \" ) return None _get_local_flora ( flora_config ) \u00a4 _get_local_flora fetch flora from the local folder or file. There are two scenarios: The flora is one aggregated local json file. The flora is a folder that contains folders of dataset ids. Source code in dataherb/flora.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 def _get_local_flora ( self , flora_config : Path ) -> List [ Herb ]: \"\"\" _get_local_flora fetch flora from the local folder or file. There are two scenarios: - The flora is one aggregated local json file. - The flora is a folder that contains folders of dataset ids. \"\"\" if self . is_aggregated : with open ( flora_config , \"r\" ) as f : json_flora = json . load ( f ) else : flora_folder = Path ( flora_config ) herb_paths = [ f for f in flora_folder . iterdir () if f . is_dir ()] json_flora = [ json . load ( open ( f . joinpath ( \"dataherb.json\" ), \"r\" )) for f in herb_paths ] return [ Herb ( herb , base_path = self . workdir / f ' { herb . get ( \"id\" , \"\" ) } ' ) for herb in json_flora ] _get_remote_flora ( flora_config ) \u00a4 _get_remote_flora fetch flora from the remote API. Warning Currently, this mode only works for aggregated json flora. Source code in dataherb/flora.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 def _get_remote_flora ( self , flora_config : URL ) -> List [ Herb ]: \"\"\" _get_remote_flora fetch flora from the remote API. !!! warning Currently, this mode only works for aggregated json flora. \"\"\" flora_request = get_data_from_url ( flora_config ) if not flora_request . status_code == 200 : raise Exception ( \"Could not download dataherb flora from remote. status code: {} \" . format ( flora_request . status_code ) ) else : json_flora = flora_request . json () return [ Herb ( herb , base_path = self . workdir / f ' { herb . get ( \"id\" , \"\" ) } ' ) for herb in json_flora ] add ( herb ) \u00a4 Add a herb to the flora. Source code in dataherb/flora.py 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 def add ( self , herb : Union [ Herb , dict , MetaData ]) -> None : \"\"\" Add a herb to the flora. \"\"\" herb = self . _convert_to_herb ( herb ) logger . debug ( f \"adding herb with metadata: { herb . metadata } \" ) for h_exist in self . flora : if herb . id == h_exist . id : raise Exception ( f \"herb id = { herb . id } already exists\" ) self . flora . append ( herb ) if self . is_aggregated : self . save ( path = self . flora_path ) else : self . save ( herb = herb ) herb ( id ) \u00a4 herb loads the dataset as dataframes. Parameters: Name Type Description Default id str herb id required Source code in dataherb/flora.py 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 def herb ( self , id : str ) -> Optional [ Herb ]: \"\"\" herb loads the dataset as dataframes. :param id: herb id \"\"\" herbs = _search_by_ids_in_flora ( self . flora , id ) if len ( herbs ) > 1 : logger . error ( f \"Found multiple datasets with id { id } , please fix this in your flora data json file, e.g, WORKDIRECTORY/flora/flora.json.\" ) if herbs : herb = herbs [ 0 ] . get ( \"herb\" ) if herb : return herb else : return None else : logger . error ( f \"Could not find herb { id } \" ) return None herb_meta ( id ) \u00a4 herb loads the dataset Parameters: Name Type Description Default id str herb id of the dataset required Source code in dataherb/flora.py 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 def herb_meta ( self , id : str ) -> Optional [ dict ]: \"\"\" herb loads the dataset :param id: herb id of the dataset \"\"\" herbs = _search_by_ids_in_flora ( self . flora , id ) if herbs : herb = herbs [ 0 ] . get ( \"herb\" ) if herb : return herb . metadata else : return None else : return None remove ( herb_id ) \u00a4 Removes a herb from the flora. Source code in dataherb/flora.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def remove ( self , herb_id : str ) -> None : \"\"\" Removes a herb from the flora. \"\"\" for id in [ i . id for i in self . flora ]: if id == herb_id : logger . debug ( f \"found herb id = { herb_id } \" ) self . flora = [ h for h in self . flora if h . id != herb_id ] if self . is_aggregated : self . save ( path = self . flora_path ) else : self . remove_herb_from_flora ( herb_id ) remove_herb_from_flora ( id , path = None ) \u00a4 Remove a herb metadata to json file Source code in dataherb/flora.py 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 def remove_herb_from_flora ( self , id : str , path : Optional [ Path ] = None ) -> None : \"\"\"Remove a herb metadata to json file\"\"\" if path is None : path = self . workdir / f \" { id } \" if not path . exists (): logger . debug ( f \"dataherb { id } doesn't exist\" ) return else : try : shutil . rmtree ( path ) except OSError as e : logger . error ( f \"Can not remove herb id { id } : { e . filename } - { e . strerror } .\" ) save ( path = None , id = None , herb = None ) \u00a4 save flora metadata to json file Source code in dataherb/flora.py 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 def save ( self , path : Optional [ Path ] = None , id : Optional [ str ] = None , herb : Optional [ Herb ] = None , ) -> None : \"\"\"save flora metadata to json file\"\"\" if path is None : path = self . flora_path logger . debug ( f \"type of a herb in flora: { type ( self . flora [ 0 ]) } \\n { self . flora [ 0 ] . metadata } \" ) if self . is_aggregated : serialized_flora = [] for h in self . flora : logger . debug ( f \"herb (type { type ( h ) } ): { h } \" ) serialized_flora . append ( h . metadata ) with open ( path , \"w\" ) as fp : json . dump ( serialized_flora , fp , sort_keys = True , indent = 4 , separators = ( \",\" , \": \" ), ) else : if ( not id ) and ( not herb ): raise Exception ( \"dataherb id must be provided\" ) elif herb : logger . debug ( f \"Saving herb using herb object\" ) self . save_herb_meta ( id = herb . id , path = path / f \" { herb . id } \" ) elif id : logger . debug ( f \"Saving herb using herb id\" ) self . save_herb_meta ( id , path / f \" { id } \" ) save_herb_meta ( id , path = None ) \u00a4 Save a herb metadata to json file Source code in dataherb/flora.py 191 192 193 194 195 196 197 198 199 200 201 202 203 def save_herb_meta ( self , id : str , path : Optional [ Path ] = None ) -> None : \"\"\"Save a herb metadata to json file\"\"\" if path is None : path = self . workdir / f \" { id } \" if not path . exists (): path . mkdir ( parents = True ) logger . debug ( f \"Will replace dataherb id { id } \" ) with open ( path / \"dataherb.json\" , \"w\" ) as fp : json . dump ( self . herb_meta ( id ), fp , sort_keys = True , indent = 4 , separators = ( \",\" , \": \" ) ) search ( keywords ) \u00a4 search finds the datasets that matches the keywords Parameters: Name Type Description Default keywords Union [ str , List [ str ]] keywords to be searched required Source code in dataherb/flora.py 221 222 223 224 225 226 227 228 229 230 def search ( self , keywords : Union [ str , List [ str ]]) -> List [ dict ]: \"\"\" search finds the datasets that matches the keywords :param keywords: keywords to be searched \"\"\" if isinstance ( keywords , str ): keywords = [ keywords ] return search_by_keywords_in_flora ( flora = self . flora , keywords = keywords )","title":"dataherb.flora"},{"location":"references/flora/#dataherbflora","text":"","title":"dataherb.flora"},{"location":"references/flora/#dataherb.flora.Flora","text":"A container of datasets. It loads a local folder of dataset metadata and forms a list of dataset objects. The provided local path or remote resource will then be converted to a list of dataherb objects. Parameters: Name Type Description Default flora path to the flora database. Either an URL or a local path. required is_aggregated bool if True, the flora is aggregated into one json file. False Source code in dataherb/flora.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 class Flora : \"\"\" A container of datasets. It loads a local folder of dataset metadata and forms a list of dataset objects. The provided local path or remote resource will then be converted to a list of dataherb objects. :param flora: path to the flora database. Either an URL or a local path. :param is_aggregated: if True, the flora is aggregated into one json file. \"\"\" def __init__ ( self , flora_path : Union [ Path , URL ], is_aggregated : bool = False ): self . is_aggregated = is_aggregated if not isinstance ( flora_path , ( Path , URL )): raise Exception ( f \"flora must be a path or a url. ( { flora_path } )\" ) if isinstance ( flora_path , URL ): self . flora = self . _get_remote_flora ( flora_path ) if isinstance ( flora_path , Path ): if flora_path . suffix == \".json\" : self . is_aggregated = True self . workdir = flora_path . parent . parent self . flora_path = flora_path self . flora = self . _get_local_flora ( flora_path ) if is_aggregated != self . is_aggregated : logger . warning ( f \"flora has is_aggregated= { self . is_aggregated } , \" \"but was specified as is_aggregated= {is_aggregated} .\" ) logger . debug ( f \"flora workdir { self . workdir } \" ) def _get_local_flora ( self , flora_config : Path ) -> List [ Herb ]: \"\"\" _get_local_flora fetch flora from the local folder or file. There are two scenarios: - The flora is one aggregated local json file. - The flora is a folder that contains folders of dataset ids. \"\"\" if self . is_aggregated : with open ( flora_config , \"r\" ) as f : json_flora = json . load ( f ) else : flora_folder = Path ( flora_config ) herb_paths = [ f for f in flora_folder . iterdir () if f . is_dir ()] json_flora = [ json . load ( open ( f . joinpath ( \"dataherb.json\" ), \"r\" )) for f in herb_paths ] return [ Herb ( herb , base_path = self . workdir / f ' { herb . get ( \"id\" , \"\" ) } ' ) for herb in json_flora ] def _get_remote_flora ( self , flora_config : URL ) -> List [ Herb ]: \"\"\" _get_remote_flora fetch flora from the remote API. !!! warning Currently, this mode only works for aggregated json flora. \"\"\" flora_request = get_data_from_url ( flora_config ) if not flora_request . status_code == 200 : raise Exception ( \"Could not download dataherb flora from remote. status code: {} \" . format ( flora_request . status_code ) ) else : json_flora = flora_request . json () return [ Herb ( herb , base_path = self . workdir / f ' { herb . get ( \"id\" , \"\" ) } ' ) for herb in json_flora ] def add ( self , herb : Union [ Herb , dict , MetaData ]) -> None : \"\"\" Add a herb to the flora. \"\"\" herb = self . _convert_to_herb ( herb ) logger . debug ( f \"adding herb with metadata: { herb . metadata } \" ) for h_exist in self . flora : if herb . id == h_exist . id : raise Exception ( f \"herb id = { herb . id } already exists\" ) self . flora . append ( herb ) if self . is_aggregated : self . save ( path = self . flora_path ) else : self . save ( herb = herb ) def _convert_to_herb ( self , herb : Union [ Herb , dict , MetaData ]) -> Herb : if isinstance ( herb , MetaData ): herb = Herb ( herb . metadata ) elif isinstance ( herb , dict ): herb = Herb ( herb ) elif isinstance ( herb , Herb ): pass else : raise Exception ( f \"Input herb type ( { type ( herb ) } ) is not supported.\" ) return herb def remove ( self , herb_id : str ) -> None : \"\"\" Removes a herb from the flora. \"\"\" for id in [ i . id for i in self . flora ]: if id == herb_id : logger . debug ( f \"found herb id = { herb_id } \" ) self . flora = [ h for h in self . flora if h . id != herb_id ] if self . is_aggregated : self . save ( path = self . flora_path ) else : self . remove_herb_from_flora ( herb_id ) def save ( self , path : Optional [ Path ] = None , id : Optional [ str ] = None , herb : Optional [ Herb ] = None , ) -> None : \"\"\"save flora metadata to json file\"\"\" if path is None : path = self . flora_path logger . debug ( f \"type of a herb in flora: { type ( self . flora [ 0 ]) } \\n { self . flora [ 0 ] . metadata } \" ) if self . is_aggregated : serialized_flora = [] for h in self . flora : logger . debug ( f \"herb (type { type ( h ) } ): { h } \" ) serialized_flora . append ( h . metadata ) with open ( path , \"w\" ) as fp : json . dump ( serialized_flora , fp , sort_keys = True , indent = 4 , separators = ( \",\" , \": \" ), ) else : if ( not id ) and ( not herb ): raise Exception ( \"dataherb id must be provided\" ) elif herb : logger . debug ( f \"Saving herb using herb object\" ) self . save_herb_meta ( id = herb . id , path = path / f \" { herb . id } \" ) elif id : logger . debug ( f \"Saving herb using herb id\" ) self . save_herb_meta ( id , path / f \" { id } \" ) def save_herb_meta ( self , id : str , path : Optional [ Path ] = None ) -> None : \"\"\"Save a herb metadata to json file\"\"\" if path is None : path = self . workdir / f \" { id } \" if not path . exists (): path . mkdir ( parents = True ) logger . debug ( f \"Will replace dataherb id { id } \" ) with open ( path / \"dataherb.json\" , \"w\" ) as fp : json . dump ( self . herb_meta ( id ), fp , sort_keys = True , indent = 4 , separators = ( \",\" , \": \" ) ) def remove_herb_from_flora ( self , id : str , path : Optional [ Path ] = None ) -> None : \"\"\"Remove a herb metadata to json file\"\"\" if path is None : path = self . workdir / f \" { id } \" if not path . exists (): logger . debug ( f \"dataherb { id } doesn't exist\" ) return else : try : shutil . rmtree ( path ) except OSError as e : logger . error ( f \"Can not remove herb id { id } : { e . filename } - { e . strerror } .\" ) def search ( self , keywords : Union [ str , List [ str ]]) -> List [ dict ]: \"\"\" search finds the datasets that matches the keywords :param keywords: keywords to be searched \"\"\" if isinstance ( keywords , str ): keywords = [ keywords ] return search_by_keywords_in_flora ( flora = self . flora , keywords = keywords ) def herb_meta ( self , id : str ) -> Optional [ dict ]: \"\"\" herb loads the dataset :param id: herb id of the dataset \"\"\" herbs = _search_by_ids_in_flora ( self . flora , id ) if herbs : herb = herbs [ 0 ] . get ( \"herb\" ) if herb : return herb . metadata else : return None else : return None def herb ( self , id : str ) -> Optional [ Herb ]: \"\"\" herb loads the dataset as dataframes. :param id: herb id \"\"\" herbs = _search_by_ids_in_flora ( self . flora , id ) if len ( herbs ) > 1 : logger . error ( f \"Found multiple datasets with id { id } , please fix this in your flora data json file, e.g, WORKDIRECTORY/flora/flora.json.\" ) if herbs : herb = herbs [ 0 ] . get ( \"herb\" ) if herb : return herb else : return None else : logger . error ( f \"Could not find herb { id } \" ) return None","title":"Flora"},{"location":"references/flora/#dataherb.flora.Flora._get_local_flora","text":"_get_local_flora fetch flora from the local folder or file. There are two scenarios: The flora is one aggregated local json file. The flora is a folder that contains folders of dataset ids. Source code in dataherb/flora.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 def _get_local_flora ( self , flora_config : Path ) -> List [ Herb ]: \"\"\" _get_local_flora fetch flora from the local folder or file. There are two scenarios: - The flora is one aggregated local json file. - The flora is a folder that contains folders of dataset ids. \"\"\" if self . is_aggregated : with open ( flora_config , \"r\" ) as f : json_flora = json . load ( f ) else : flora_folder = Path ( flora_config ) herb_paths = [ f for f in flora_folder . iterdir () if f . is_dir ()] json_flora = [ json . load ( open ( f . joinpath ( \"dataherb.json\" ), \"r\" )) for f in herb_paths ] return [ Herb ( herb , base_path = self . workdir / f ' { herb . get ( \"id\" , \"\" ) } ' ) for herb in json_flora ]","title":"_get_local_flora()"},{"location":"references/flora/#dataherb.flora.Flora._get_remote_flora","text":"_get_remote_flora fetch flora from the remote API. Warning Currently, this mode only works for aggregated json flora. Source code in dataherb/flora.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 def _get_remote_flora ( self , flora_config : URL ) -> List [ Herb ]: \"\"\" _get_remote_flora fetch flora from the remote API. !!! warning Currently, this mode only works for aggregated json flora. \"\"\" flora_request = get_data_from_url ( flora_config ) if not flora_request . status_code == 200 : raise Exception ( \"Could not download dataherb flora from remote. status code: {} \" . format ( flora_request . status_code ) ) else : json_flora = flora_request . json () return [ Herb ( herb , base_path = self . workdir / f ' { herb . get ( \"id\" , \"\" ) } ' ) for herb in json_flora ]","title":"_get_remote_flora()"},{"location":"references/flora/#dataherb.flora.Flora.add","text":"Add a herb to the flora. Source code in dataherb/flora.py 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 def add ( self , herb : Union [ Herb , dict , MetaData ]) -> None : \"\"\" Add a herb to the flora. \"\"\" herb = self . _convert_to_herb ( herb ) logger . debug ( f \"adding herb with metadata: { herb . metadata } \" ) for h_exist in self . flora : if herb . id == h_exist . id : raise Exception ( f \"herb id = { herb . id } already exists\" ) self . flora . append ( herb ) if self . is_aggregated : self . save ( path = self . flora_path ) else : self . save ( herb = herb )","title":"add()"},{"location":"references/flora/#dataherb.flora.Flora.herb","text":"herb loads the dataset as dataframes. Parameters: Name Type Description Default id str herb id required Source code in dataherb/flora.py 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 def herb ( self , id : str ) -> Optional [ Herb ]: \"\"\" herb loads the dataset as dataframes. :param id: herb id \"\"\" herbs = _search_by_ids_in_flora ( self . flora , id ) if len ( herbs ) > 1 : logger . error ( f \"Found multiple datasets with id { id } , please fix this in your flora data json file, e.g, WORKDIRECTORY/flora/flora.json.\" ) if herbs : herb = herbs [ 0 ] . get ( \"herb\" ) if herb : return herb else : return None else : logger . error ( f \"Could not find herb { id } \" ) return None","title":"herb()"},{"location":"references/flora/#dataherb.flora.Flora.herb_meta","text":"herb loads the dataset Parameters: Name Type Description Default id str herb id of the dataset required Source code in dataherb/flora.py 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 def herb_meta ( self , id : str ) -> Optional [ dict ]: \"\"\" herb loads the dataset :param id: herb id of the dataset \"\"\" herbs = _search_by_ids_in_flora ( self . flora , id ) if herbs : herb = herbs [ 0 ] . get ( \"herb\" ) if herb : return herb . metadata else : return None else : return None","title":"herb_meta()"},{"location":"references/flora/#dataherb.flora.Flora.remove","text":"Removes a herb from the flora. Source code in dataherb/flora.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def remove ( self , herb_id : str ) -> None : \"\"\" Removes a herb from the flora. \"\"\" for id in [ i . id for i in self . flora ]: if id == herb_id : logger . debug ( f \"found herb id = { herb_id } \" ) self . flora = [ h for h in self . flora if h . id != herb_id ] if self . is_aggregated : self . save ( path = self . flora_path ) else : self . remove_herb_from_flora ( herb_id )","title":"remove()"},{"location":"references/flora/#dataherb.flora.Flora.remove_herb_from_flora","text":"Remove a herb metadata to json file Source code in dataherb/flora.py 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 def remove_herb_from_flora ( self , id : str , path : Optional [ Path ] = None ) -> None : \"\"\"Remove a herb metadata to json file\"\"\" if path is None : path = self . workdir / f \" { id } \" if not path . exists (): logger . debug ( f \"dataherb { id } doesn't exist\" ) return else : try : shutil . rmtree ( path ) except OSError as e : logger . error ( f \"Can not remove herb id { id } : { e . filename } - { e . strerror } .\" )","title":"remove_herb_from_flora()"},{"location":"references/flora/#dataherb.flora.Flora.save","text":"save flora metadata to json file Source code in dataherb/flora.py 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 def save ( self , path : Optional [ Path ] = None , id : Optional [ str ] = None , herb : Optional [ Herb ] = None , ) -> None : \"\"\"save flora metadata to json file\"\"\" if path is None : path = self . flora_path logger . debug ( f \"type of a herb in flora: { type ( self . flora [ 0 ]) } \\n { self . flora [ 0 ] . metadata } \" ) if self . is_aggregated : serialized_flora = [] for h in self . flora : logger . debug ( f \"herb (type { type ( h ) } ): { h } \" ) serialized_flora . append ( h . metadata ) with open ( path , \"w\" ) as fp : json . dump ( serialized_flora , fp , sort_keys = True , indent = 4 , separators = ( \",\" , \": \" ), ) else : if ( not id ) and ( not herb ): raise Exception ( \"dataherb id must be provided\" ) elif herb : logger . debug ( f \"Saving herb using herb object\" ) self . save_herb_meta ( id = herb . id , path = path / f \" { herb . id } \" ) elif id : logger . debug ( f \"Saving herb using herb id\" ) self . save_herb_meta ( id , path / f \" { id } \" )","title":"save()"},{"location":"references/flora/#dataherb.flora.Flora.save_herb_meta","text":"Save a herb metadata to json file Source code in dataherb/flora.py 191 192 193 194 195 196 197 198 199 200 201 202 203 def save_herb_meta ( self , id : str , path : Optional [ Path ] = None ) -> None : \"\"\"Save a herb metadata to json file\"\"\" if path is None : path = self . workdir / f \" { id } \" if not path . exists (): path . mkdir ( parents = True ) logger . debug ( f \"Will replace dataherb id { id } \" ) with open ( path / \"dataherb.json\" , \"w\" ) as fp : json . dump ( self . herb_meta ( id ), fp , sort_keys = True , indent = 4 , separators = ( \",\" , \": \" ) )","title":"save_herb_meta()"},{"location":"references/flora/#dataherb.flora.Flora.search","text":"search finds the datasets that matches the keywords Parameters: Name Type Description Default keywords Union [ str , List [ str ]] keywords to be searched required Source code in dataherb/flora.py 221 222 223 224 225 226 227 228 229 230 def search ( self , keywords : Union [ str , List [ str ]]) -> List [ dict ]: \"\"\" search finds the datasets that matches the keywords :param keywords: keywords to be searched \"\"\" if isinstance ( keywords , str ): keywords = [ keywords ] return search_by_keywords_in_flora ( flora = self . flora , keywords = keywords )","title":"search()"},{"location":"references/cmd/","text":"CMD \u00a4","title":"CMD"},{"location":"references/cmd/#cmd","text":"","title":"CMD"},{"location":"references/cmd/create/","text":"cmd.create \u00a4 describe_dataset () \u00a4 describe_dataset asks the user to specify some basic info about the dataset Source code in dataherb/cmd/create.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 def describe_dataset () -> dict : \"\"\" describe_dataset asks the user to specify some basic info about the dataset \"\"\" questions = [ inquirer . List ( \"source\" , message = \"Where is/will be the dataset synced to?\" , choices = [ \"git\" , \"s3\" ], ), inquirer . Text ( \"name\" , message = \"How would you like to name the dataset?\" ), inquirer . Text ( \"id\" , message = \"Please specify a unique id for the dataset\" ), inquirer . Text ( \"description\" , message = \"What is the dataset about? This will be the description of the dataset.\" , ), inquirer . Text ( \"uri\" , message = \"What is the dataset's URI? This will be the URI of the dataset.\" , ), ] answers = inquirer . prompt ( questions ) metadata_uri = get_metadata_uri ( answers ) meta = { \"source\" : answers . get ( \"source\" ), \"name\" : answers . get ( \"name\" , \"\" ), \"id\" : answers [ \"id\" ], \"description\" : answers . get ( \"description\" , \"\" ), \"uri\" : answers . get ( \"uri\" , \"\" ), \"metadata_uri\" : metadata_uri , } return meta get_metadata_uri ( answers , branch = 'main' ) \u00a4 get_metadata_uri reconstructs the datapackage uri from the user's answers. Parameters: Name Type Description Default answers dict answers from inquirer prompt required Source code in dataherb/cmd/create.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 def get_metadata_uri ( answers : dict , branch : str = \"main\" ) -> str : \"\"\" get_metadata_uri reconstructs the datapackage uri from the user's answers. :param answers: answers from inquirer prompt \"\"\" if answers . get ( \"source\" ) == \"git\" : git_repo_link = answers . get ( \"uri\" , \"\" ) git_repo = \"/\" . join ( git_repo_link [: - 4 ] . split ( \"/\" )[ - 2 :]) metadata_uri = ( f \"https://raw.githubusercontent.com/ { git_repo } / { branch } /dataherb.json\" ) elif answers . get ( \"source\" ) == \"s3\" : s3_uri = answers . get ( \"uri\" , \"\" ) if s3_uri . endswith ( \"/\" ): s3_uri = s3_uri [: - 1 ] metadata_uri = f \" { s3_uri } /dataherb.json\" else : click . echo ( f 'source type { answers . get ( \"source\" ) } is not supported.' ) return metadata_uri","title":"cmd.create"},{"location":"references/cmd/create/#cmdcreate","text":"","title":"cmd.create"},{"location":"references/cmd/create/#dataherb.cmd.create.describe_dataset","text":"describe_dataset asks the user to specify some basic info about the dataset Source code in dataherb/cmd/create.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 def describe_dataset () -> dict : \"\"\" describe_dataset asks the user to specify some basic info about the dataset \"\"\" questions = [ inquirer . List ( \"source\" , message = \"Where is/will be the dataset synced to?\" , choices = [ \"git\" , \"s3\" ], ), inquirer . Text ( \"name\" , message = \"How would you like to name the dataset?\" ), inquirer . Text ( \"id\" , message = \"Please specify a unique id for the dataset\" ), inquirer . Text ( \"description\" , message = \"What is the dataset about? This will be the description of the dataset.\" , ), inquirer . Text ( \"uri\" , message = \"What is the dataset's URI? This will be the URI of the dataset.\" , ), ] answers = inquirer . prompt ( questions ) metadata_uri = get_metadata_uri ( answers ) meta = { \"source\" : answers . get ( \"source\" ), \"name\" : answers . get ( \"name\" , \"\" ), \"id\" : answers [ \"id\" ], \"description\" : answers . get ( \"description\" , \"\" ), \"uri\" : answers . get ( \"uri\" , \"\" ), \"metadata_uri\" : metadata_uri , } return meta","title":"describe_dataset()"},{"location":"references/cmd/create/#dataherb.cmd.create.get_metadata_uri","text":"get_metadata_uri reconstructs the datapackage uri from the user's answers. Parameters: Name Type Description Default answers dict answers from inquirer prompt required Source code in dataherb/cmd/create.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 def get_metadata_uri ( answers : dict , branch : str = \"main\" ) -> str : \"\"\" get_metadata_uri reconstructs the datapackage uri from the user's answers. :param answers: answers from inquirer prompt \"\"\" if answers . get ( \"source\" ) == \"git\" : git_repo_link = answers . get ( \"uri\" , \"\" ) git_repo = \"/\" . join ( git_repo_link [: - 4 ] . split ( \"/\" )[ - 2 :]) metadata_uri = ( f \"https://raw.githubusercontent.com/ { git_repo } / { branch } /dataherb.json\" ) elif answers . get ( \"source\" ) == \"s3\" : s3_uri = answers . get ( \"uri\" , \"\" ) if s3_uri . endswith ( \"/\" ): s3_uri = s3_uri [: - 1 ] metadata_uri = f \" { s3_uri } /dataherb.json\" else : click . echo ( f 'source type { answers . get ( \"source\" ) } is not supported.' ) return metadata_uri","title":"get_metadata_uri()"},{"location":"references/cmd/search/","text":"cmd.search \u00a4 HerbTable \u00a4 Format a herb object as a table. For example, a flora search result can be formatted as a table for the user to read easily. Parameters: Name Type Description Default herb Herb an Herb object required Source code in dataherb/cmd/search.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 class HerbTable : \"\"\"Format a herb object as a table. For example, a flora search result can be formatted as a table for the user to read easily. :param herb: an Herb object \"\"\" def __init__ ( self , herb : Herb ): self . herb = herb def panel ( self ) -> Dict [ str , Panel ]: \"\"\"Create a panel with all the information\"\"\" return { \"table\" : self . table (), \"tree\" : self . resource_tree (), } def table ( self ) -> Panel : \"\"\"Summary Table\"\"\" table = Table ( title = f \"DataHerb: { self . herb . name } \" , show_lines = True ) table . add_column ( \"key\" , justify = \"right\" , style = \"cyan\" , no_wrap = False ) table . add_column ( \"value\" , style = \"magenta\" , no_wrap = False ) table . add_row ( f \"ID\" , f \" { self . herb . id } \" ) table . add_row ( f \"Name\" , f \" { self . herb . name } \" ) table . add_row ( f \"Source\" , f \" { self . herb . source } \" ) table . add_row ( f \"Description\" , f \" { self . herb . description } \" ) table . add_row ( f \"URI\" , f \" { self . herb . uri } \" ) table . add_row ( f \"Metadata\" , f \" { self . herb . metadata_uri } \" ) pl = Panel ( table , title = f \"Summary of { self . herb . id } \" ) return pl def resource_tree ( self ) -> Panel : \"\"\"Show list of resources\"\"\" tree = Tree ( f \" { self . herb . id } \" ) for r in self . herb . resources : tree . add ( f ' { r . descriptor . get ( \"path\" ) } ' ) pl = Panel ( tree , title = f \"Resources of { self . herb . id } \" ) return pl panel () \u00a4 Create a panel with all the information Source code in dataherb/cmd/search.py 20 21 22 23 24 25 26 def panel ( self ) -> Dict [ str , Panel ]: \"\"\"Create a panel with all the information\"\"\" return { \"table\" : self . table (), \"tree\" : self . resource_tree (), } resource_tree () \u00a4 Show list of resources Source code in dataherb/cmd/search.py 46 47 48 49 50 51 52 53 54 55 def resource_tree ( self ) -> Panel : \"\"\"Show list of resources\"\"\" tree = Tree ( f \" { self . herb . id } \" ) for r in self . herb . resources : tree . add ( f ' { r . descriptor . get ( \"path\" ) } ' ) pl = Panel ( tree , title = f \"Resources of { self . herb . id } \" ) return pl table () \u00a4 Summary Table Source code in dataherb/cmd/search.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def table ( self ) -> Panel : \"\"\"Summary Table\"\"\" table = Table ( title = f \"DataHerb: { self . herb . name } \" , show_lines = True ) table . add_column ( \"key\" , justify = \"right\" , style = \"cyan\" , no_wrap = False ) table . add_column ( \"value\" , style = \"magenta\" , no_wrap = False ) table . add_row ( f \"ID\" , f \" { self . herb . id } \" ) table . add_row ( f \"Name\" , f \" { self . herb . name } \" ) table . add_row ( f \"Source\" , f \" { self . herb . source } \" ) table . add_row ( f \"Description\" , f \" { self . herb . description } \" ) table . add_row ( f \"URI\" , f \" { self . herb . uri } \" ) table . add_row ( f \"Metadata\" , f \" { self . herb . metadata_uri } \" ) pl = Panel ( table , title = f \"Summary of { self . herb . id } \" ) return pl","title":"cmd.search"},{"location":"references/cmd/search/#cmdsearch","text":"","title":"cmd.search"},{"location":"references/cmd/search/#dataherb.cmd.search.HerbTable","text":"Format a herb object as a table. For example, a flora search result can be formatted as a table for the user to read easily. Parameters: Name Type Description Default herb Herb an Herb object required Source code in dataherb/cmd/search.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 class HerbTable : \"\"\"Format a herb object as a table. For example, a flora search result can be formatted as a table for the user to read easily. :param herb: an Herb object \"\"\" def __init__ ( self , herb : Herb ): self . herb = herb def panel ( self ) -> Dict [ str , Panel ]: \"\"\"Create a panel with all the information\"\"\" return { \"table\" : self . table (), \"tree\" : self . resource_tree (), } def table ( self ) -> Panel : \"\"\"Summary Table\"\"\" table = Table ( title = f \"DataHerb: { self . herb . name } \" , show_lines = True ) table . add_column ( \"key\" , justify = \"right\" , style = \"cyan\" , no_wrap = False ) table . add_column ( \"value\" , style = \"magenta\" , no_wrap = False ) table . add_row ( f \"ID\" , f \" { self . herb . id } \" ) table . add_row ( f \"Name\" , f \" { self . herb . name } \" ) table . add_row ( f \"Source\" , f \" { self . herb . source } \" ) table . add_row ( f \"Description\" , f \" { self . herb . description } \" ) table . add_row ( f \"URI\" , f \" { self . herb . uri } \" ) table . add_row ( f \"Metadata\" , f \" { self . herb . metadata_uri } \" ) pl = Panel ( table , title = f \"Summary of { self . herb . id } \" ) return pl def resource_tree ( self ) -> Panel : \"\"\"Show list of resources\"\"\" tree = Tree ( f \" { self . herb . id } \" ) for r in self . herb . resources : tree . add ( f ' { r . descriptor . get ( \"path\" ) } ' ) pl = Panel ( tree , title = f \"Resources of { self . herb . id } \" ) return pl","title":"HerbTable"},{"location":"references/cmd/search/#dataherb.cmd.search.HerbTable.panel","text":"Create a panel with all the information Source code in dataherb/cmd/search.py 20 21 22 23 24 25 26 def panel ( self ) -> Dict [ str , Panel ]: \"\"\"Create a panel with all the information\"\"\" return { \"table\" : self . table (), \"tree\" : self . resource_tree (), }","title":"panel()"},{"location":"references/cmd/search/#dataherb.cmd.search.HerbTable.resource_tree","text":"Show list of resources Source code in dataherb/cmd/search.py 46 47 48 49 50 51 52 53 54 55 def resource_tree ( self ) -> Panel : \"\"\"Show list of resources\"\"\" tree = Tree ( f \" { self . herb . id } \" ) for r in self . herb . resources : tree . add ( f ' { r . descriptor . get ( \"path\" ) } ' ) pl = Panel ( tree , title = f \"Resources of { self . herb . id } \" ) return pl","title":"resource_tree()"},{"location":"references/cmd/search/#dataherb.cmd.search.HerbTable.table","text":"Summary Table Source code in dataherb/cmd/search.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def table ( self ) -> Panel : \"\"\"Summary Table\"\"\" table = Table ( title = f \"DataHerb: { self . herb . name } \" , show_lines = True ) table . add_column ( \"key\" , justify = \"right\" , style = \"cyan\" , no_wrap = False ) table . add_column ( \"value\" , style = \"magenta\" , no_wrap = False ) table . add_row ( f \"ID\" , f \" { self . herb . id } \" ) table . add_row ( f \"Name\" , f \" { self . herb . name } \" ) table . add_row ( f \"Source\" , f \" { self . herb . source } \" ) table . add_row ( f \"Description\" , f \" { self . herb . description } \" ) table . add_row ( f \"URI\" , f \" { self . herb . uri } \" ) table . add_row ( f \"Metadata\" , f \" { self . herb . metadata_uri } \" ) pl = Panel ( table , title = f \"Summary of { self . herb . id } \" ) return pl","title":"table()"},{"location":"references/cmd/sync_git/","text":"cmd.sync_git \u00a4 get_dataherb ( source ) \u00a4 get dataherb.json from source Parameters: Name Type Description Default source Path local folder required Source code in dataherb/cmd/sync_git.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def get_dataherb ( source : Path ) -> dict : \"\"\" get dataherb.json from source :param source: local folder \"\"\" if not ( source / \"dataherb.json\" ) . exists (): click . echo ( f \"No dataherb.json found in { source } . Please run `dataherb create` first.\" ) sys . exit () with open ( source / \"dataherb.json\" , \"r\" ) as f : data = json . load ( f ) return data is_git_repo ( path ) \u00a4 checks if path is a git repo Parameters: Name Type Description Default path Path path to check required Source code in dataherb/cmd/sync_git.py 11 12 13 14 15 16 17 18 19 20 21 def is_git_repo ( path : Path ) -> bool : \"\"\" checks if path is a git repo :param path: path to check \"\"\" try : _ = git . Repo ( path ) . git_dir return True except git . exc . InvalidGitRepositoryError : return False remote_git_repo ( metadata_url ) \u00a4 parse a remote git repo url Parameters: Name Type Description Default metadata_url str remote url to metadata file required Source code in dataherb/cmd/sync_git.py 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 def remote_git_repo ( metadata_url : str ): \"\"\" parse a remote git repo url :param metadata_url: remote url to metadata file \"\"\" parsed = giturlparse . parse ( metadata_url ) url_host_dispatcher = { \"github.com\" : \"https://raw.githubusercontent.com\" } if parsed . host not in url_host_dispatcher : raise ValueError ( f \" { parsed . host } is not supported.\" ) return { \"metadata_uri\" : f \" { url_host_dispatcher [ parsed . host ] }{ parsed . pathname } \" , \"path\" : parsed . pathname , \"protocol\" : parsed . protocol , \"host\" : parsed . host , \"resource\" : parsed . resource , \"user\" : parsed . user , \"port\" : parsed . port , \"name\" : parsed . name , \"owner\" : parsed . owner , } upload_dataset_to_git ( source , target , experimental = False ) \u00a4 uploads local folder to remote Parameters: Name Type Description Default source Path local folder required target str remote url required experimental bool experimental flag False Source code in dataherb/cmd/sync_git.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def upload_dataset_to_git ( source : Path , target : str , experimental : bool = False ) -> None : \"\"\" uploads local folder to remote :param source: local folder :param target: remote url :param experimental: experimental flag \"\"\" is_git_initialized = is_git_repo ( source ) if not experimental : text = ( f \"git sync is still a WIP. \\n \" f \"Please go to { source } and sync your git repository to { target } manually. \\n \" ) if is_git_initialized : text += f \"Note: simply add, commit and push.\" else : text += f \"Note: git init your repo, commit, add remote { target } , and push.\" click . echo ( text ) else : if is_git_initialized : repo = git . Repo ( source ) repo . index . add ([ \"*\" ]) repo . index . commit ( \"created datset: added dataherb.json\" ) if len ( repo . remotes ) == 0 : origin = repo . create_remote ( \"origin\" , target ) assert origin . exists () origin . fetch () repo . create_head ( \"master\" , origin . refs . master ) . set_tracking_branch ( origin . refs . master ) . checkout () origin . push () else : repo . git . push () else : repo = git . Repo . init ( source ) repo . git . add ([ \"*\" ]) repo . index . commit ( \"initial commit\" ) origin = repo . create_remote ( \"origin\" , target ) assert origin . exists () origin . fetch () repo . create_head ( \"master\" , origin . refs . master ) . set_tracking_branch ( origin . refs . master ) . checkout () origin . push ()","title":"cmd.sync_git"},{"location":"references/cmd/sync_git/#cmdsync_git","text":"","title":"cmd.sync_git"},{"location":"references/cmd/sync_git/#dataherb.cmd.sync_git.get_dataherb","text":"get dataherb.json from source Parameters: Name Type Description Default source Path local folder required Source code in dataherb/cmd/sync_git.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def get_dataherb ( source : Path ) -> dict : \"\"\" get dataherb.json from source :param source: local folder \"\"\" if not ( source / \"dataherb.json\" ) . exists (): click . echo ( f \"No dataherb.json found in { source } . Please run `dataherb create` first.\" ) sys . exit () with open ( source / \"dataherb.json\" , \"r\" ) as f : data = json . load ( f ) return data","title":"get_dataherb()"},{"location":"references/cmd/sync_git/#dataherb.cmd.sync_git.is_git_repo","text":"checks if path is a git repo Parameters: Name Type Description Default path Path path to check required Source code in dataherb/cmd/sync_git.py 11 12 13 14 15 16 17 18 19 20 21 def is_git_repo ( path : Path ) -> bool : \"\"\" checks if path is a git repo :param path: path to check \"\"\" try : _ = git . Repo ( path ) . git_dir return True except git . exc . InvalidGitRepositoryError : return False","title":"is_git_repo()"},{"location":"references/cmd/sync_git/#dataherb.cmd.sync_git.remote_git_repo","text":"parse a remote git repo url Parameters: Name Type Description Default metadata_url str remote url to metadata file required Source code in dataherb/cmd/sync_git.py 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 def remote_git_repo ( metadata_url : str ): \"\"\" parse a remote git repo url :param metadata_url: remote url to metadata file \"\"\" parsed = giturlparse . parse ( metadata_url ) url_host_dispatcher = { \"github.com\" : \"https://raw.githubusercontent.com\" } if parsed . host not in url_host_dispatcher : raise ValueError ( f \" { parsed . host } is not supported.\" ) return { \"metadata_uri\" : f \" { url_host_dispatcher [ parsed . host ] }{ parsed . pathname } \" , \"path\" : parsed . pathname , \"protocol\" : parsed . protocol , \"host\" : parsed . host , \"resource\" : parsed . resource , \"user\" : parsed . user , \"port\" : parsed . port , \"name\" : parsed . name , \"owner\" : parsed . owner , }","title":"remote_git_repo()"},{"location":"references/cmd/sync_git/#dataherb.cmd.sync_git.upload_dataset_to_git","text":"uploads local folder to remote Parameters: Name Type Description Default source Path local folder required target str remote url required experimental bool experimental flag False Source code in dataherb/cmd/sync_git.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def upload_dataset_to_git ( source : Path , target : str , experimental : bool = False ) -> None : \"\"\" uploads local folder to remote :param source: local folder :param target: remote url :param experimental: experimental flag \"\"\" is_git_initialized = is_git_repo ( source ) if not experimental : text = ( f \"git sync is still a WIP. \\n \" f \"Please go to { source } and sync your git repository to { target } manually. \\n \" ) if is_git_initialized : text += f \"Note: simply add, commit and push.\" else : text += f \"Note: git init your repo, commit, add remote { target } , and push.\" click . echo ( text ) else : if is_git_initialized : repo = git . Repo ( source ) repo . index . add ([ \"*\" ]) repo . index . commit ( \"created datset: added dataherb.json\" ) if len ( repo . remotes ) == 0 : origin = repo . create_remote ( \"origin\" , target ) assert origin . exists () origin . fetch () repo . create_head ( \"master\" , origin . refs . master ) . set_tracking_branch ( origin . refs . master ) . checkout () origin . push () else : repo . git . push () else : repo = git . Repo . init ( source ) repo . git . add ([ \"*\" ]) repo . index . commit ( \"initial commit\" ) origin = repo . create_remote ( \"origin\" , target ) assert origin . exists () origin . fetch () repo . create_head ( \"master\" , origin . refs . master ) . set_tracking_branch ( origin . refs . master ) . checkout () origin . push ()","title":"upload_dataset_to_git()"},{"location":"references/cmd/sync_s3/","text":"cmd.sync_s3 \u00a4 upload_dataset_to_s3 ( source , target ) \u00a4 upload_dataset_to_s3 uploads the dataset to S3 Parameters: Name Type Description Default source str local folder required target str remote s3 uri required Source code in dataherb/cmd/sync_s3.py 4 5 6 7 8 9 10 11 12 def upload_dataset_to_s3 ( source : str , target : str ) -> None : \"\"\" upload_dataset_to_s3 uploads the dataset to S3 :param source: local folder :param target: remote s3 uri \"\"\" _aws_cli (( \"s3\" , \"sync\" , source , target ))","title":"cmd.sync_s3"},{"location":"references/cmd/sync_s3/#cmdsync_s3","text":"","title":"cmd.sync_s3"},{"location":"references/cmd/sync_s3/#dataherb.cmd.sync_s3.upload_dataset_to_s3","text":"upload_dataset_to_s3 uploads the dataset to S3 Parameters: Name Type Description Default source str local folder required target str remote s3 uri required Source code in dataherb/cmd/sync_s3.py 4 5 6 7 8 9 10 11 12 def upload_dataset_to_s3 ( source : str , target : str ) -> None : \"\"\" upload_dataset_to_s3 uploads the dataset to S3 :param source: local folder :param target: remote s3 uri \"\"\" _aws_cli (( \"s3\" , \"sync\" , source , target ))","title":"upload_dataset_to_s3()"},{"location":"references/core/base/","text":"core.base \u00a4 Herb \u00a4 Herb is a collection of the dataset. Parameters: Name Type Description Default meta_dict dict the dictionary that specifies the herb. required base_path Optional [ Path ] the path to the dataset. None with_resources whether to load the resources, i.e., data files. True Source code in dataherb/core/base.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 class Herb : \"\"\" Herb is a collection of the dataset. :param meta_dict: the dictionary that specifies the herb. :param base_path: the path to the dataset. :param with_resources: whether to load the resources, i.e., data files. \"\"\" def __init__ ( self , meta_dict : dict , base_path : Optional [ Path ] = None , with_resources = True ): \"\"\" :param meta_dict: the dictionary that specifies the herb :type meta_dict: dict :param base_path: the path to the dataset :type base_path: pathlib.Path :param with_resources: whether to load the resources, i.e., data files :type with_resources: bool \"\"\" if base_path is None : c = Config () self . base_path = c . workdir else : self . base_path = base_path if isinstance ( self . base_path , str ): self . base_path = Path ( self . base_path ) self . with_resources = with_resources if isinstance ( meta_dict , dict ): self . herb_meta_json = meta_dict elif isinstance ( meta_dict , MetaData ): logger . debug ( \"get herb_meta_json from MetaData ...\" ) self . herb_meta_json = meta_dict . metadata else : logger . debug ( f \"input meta type ( { type ( meta_dict ) } ) is not supported.\" ) click . BadParameter ( f \"input meta type ( { type ( meta_dict ) } ) is not supported.\" , param = meta_dict , ) self . _from_meta_dict ( self . herb_meta_json ) @property def is_local ( self ) -> bool : is_local = False if self . base_path . exists (): is_local = True return is_local def _from_meta_dict ( self , meta_dict : dict ) -> None : \"\"\"Build properties from meta dict\"\"\" self . name = meta_dict . get ( \"name\" ) self . description = meta_dict . get ( \"description\" ) self . repository = meta_dict . get ( \"repository\" ) # Deprecated self . id = meta_dict . get ( \"id\" , \"\" ) self . source = meta_dict . get ( \"source\" ) self . metadata_uri = meta_dict . get ( \"metadata_uri\" , \"\" ) self . uri = meta_dict . get ( \"uri\" ) self . datapackage = Package ( meta_dict . get ( \"datapackage\" )) if not self . datapackage : self . update_datapackage () if self . with_resources : self . resources = [ self . get_resource ( i , source_only = False ) for i in range ( len ( self . datapackage . resources )) ] def get_resource ( self , idx : Optional [ int ] = None , path : Optional [ str ] = None , name : Optional [ str ] = None , source_only : bool = True , ) -> Resource : if idx is None : if path : all_paths = [ r . descriptor . get ( \"path\" ) for r in self . datapackage . resources ] if path in all_paths : idx = all_paths . index ( path ) else : logger . error ( f \"path = { path } is not in resources.\" ) elif name : all_names = [ r . descriptor . get ( \"name\" ) for r in self . datapackage . resources ] if name in all_names : idx = all_names . index ( name ) else : logger . error ( f \"name = { name } is not in resources.\" ) else : raise Exception ( f \"Please specify at least one of the keywords: idx, path, name.\" ) if self . is_local : logger . debug ( f \"Using local dataset for { self . id } , sync it if you need the updated version.\" ) r = self . datapackage . resources [ idx ] logger . debug ( f \"using base_path: { str ( self . base_path ) } \" ) logger . debug ( f \"using descriptor: { r . descriptor } \" ) resource = Resource ( r . descriptor , base_path = str ( self . base_path )) logger . debug ( f \"base_path of r_1: { resource . _Resource__base_path } \" ) elif ( not self . is_local ) and ( self . source == \"git\" ): logger . debug ( f \"Using remote data\" ) self . remote_path = f \" { self . metadata_uri [: - 16 ] } \" r = self . datapackage . resources [ idx ] resource = Resource ( { ** ( r . descriptor ), ** { \"path\" : self . remote_path + r . descriptor . get ( \"path\" , \"\" )}, } ) elif ( not self . is_local ) and ( self . source == \"s3\" ): logger . debug ( f \"Using remote data\" ) logger . debug ( f \"Direct resource from S3 is not supported yet. \" f \"Please sync the dataset to local using the command line first. \\n \" f \"TODO: Sync S3 to local after confirmation from here.\" ) resource = self . datapackage . resources [ idx ] else : logger . error ( \"Resource is not supported. Currently supporting S3 and git.\" ) resource = self . datapackage . resources [ idx ] if source_only : return resource . source else : return resource def update_datapackage ( self ) -> None : \"\"\" update_datapackage gets the datapackage metadata from the metadata_uri \"\"\" if self . source == \"git\" : file_content = get_data_from_url ( self . metadata_uri ) if not file_content . status_code == 200 : file_error_msg = \"Could not fetch remote file: {} ; {} \" . format ( self . metadata_uri , file_content . status_code ) click . ClickException ( file_error_msg ) # file_content = json.dumps([{\"url\": self.url, \"error\": file_error_msg}]) else : file_content = file_content . json () # .decode(self.decode) elif self . source == \"s3\" : raise NotImplementedError ( \"Directly get dataherb.json from S3 is not yet implemented.\" ) self . datapackage_meta = file_content self . herb_meta_json [ \"datapackage\" ] = self . datapackage_meta self . datapackage = Package ( self . datapackage_meta ) return self . datapackage def search_score ( self , keywords : Union [ List [ str ], Tuple [ str ], Set [ str ]], keys : Optional [ List [ str ]] = None , ) -> float : \"\"\" search_score calcualtes the matching score of the herb for any given keyword :param keywords: keywords for the search :type keywords: list :param keys: list of keys in the dictionary to look into. :type keys: list, optional \"\"\" if keys is None : keys = [ \"name\" , \"id\" , \"repository\" , \"tags\" , \"description\" ] if not isinstance ( keywords , ( list , tuple , set )): keywords = [ keywords ] herb_for_search = { key : val for key , val in self . herb_meta_json . items () if key in keys } herb_for_search = _flatten_dict ( herb_for_search ) keywords_scores = [] for keyword in keywords : for key , val in herb_for_search . items (): score = fuzz . token_set_ratio ( val , keyword ) keywords_scores . append ( score ) max_score = 0 if keywords_scores : max_score = max ( keywords_scores ) return max_score @property def metadata ( self ): \"\"\" metadata formats the metadata of the herb \"\"\" return self . herb_meta_json . copy () def download ( self ): \"\"\" download downloads the dataset \"\"\" raise NotImplementedError ( \"Not implemented\" ) # data_files = [] # for leaf_meta in self.herb_meta_json.get(\"data\"): # leaf = Leaf(leaf_meta, self) # data_files.append(leaf.download()) # return data_files def __str__ ( self ): meta = self . metadata authors = meta . get ( \"contributors\" , []) authors = \", \" . join ([ author . get ( \"name\" ) for author in authors ]) return ( f \"DataHerb ID: { meta . get ( 'id' ) } \\n \" f \"name: { meta . get ( 'name' ) } \" f \"description: { meta . get ( 'description' ) } \\n \" f \"contributors: { authors } \" ) metadata property \u00a4 metadata formats the metadata of the herb __init__ ( meta_dict , base_path = None , with_resources = True ) \u00a4 Parameters: Name Type Description Default meta_dict dict the dictionary that specifies the herb required base_path Optional [ Path ] the path to the dataset None with_resources bool whether to load the resources, i.e., data files True Source code in dataherb/core/base.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 def __init__ ( self , meta_dict : dict , base_path : Optional [ Path ] = None , with_resources = True ): \"\"\" :param meta_dict: the dictionary that specifies the herb :type meta_dict: dict :param base_path: the path to the dataset :type base_path: pathlib.Path :param with_resources: whether to load the resources, i.e., data files :type with_resources: bool \"\"\" if base_path is None : c = Config () self . base_path = c . workdir else : self . base_path = base_path if isinstance ( self . base_path , str ): self . base_path = Path ( self . base_path ) self . with_resources = with_resources if isinstance ( meta_dict , dict ): self . herb_meta_json = meta_dict elif isinstance ( meta_dict , MetaData ): logger . debug ( \"get herb_meta_json from MetaData ...\" ) self . herb_meta_json = meta_dict . metadata else : logger . debug ( f \"input meta type ( { type ( meta_dict ) } ) is not supported.\" ) click . BadParameter ( f \"input meta type ( { type ( meta_dict ) } ) is not supported.\" , param = meta_dict , ) self . _from_meta_dict ( self . herb_meta_json ) _from_meta_dict ( meta_dict ) \u00a4 Build properties from meta dict Source code in dataherb/core/base.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def _from_meta_dict ( self , meta_dict : dict ) -> None : \"\"\"Build properties from meta dict\"\"\" self . name = meta_dict . get ( \"name\" ) self . description = meta_dict . get ( \"description\" ) self . repository = meta_dict . get ( \"repository\" ) # Deprecated self . id = meta_dict . get ( \"id\" , \"\" ) self . source = meta_dict . get ( \"source\" ) self . metadata_uri = meta_dict . get ( \"metadata_uri\" , \"\" ) self . uri = meta_dict . get ( \"uri\" ) self . datapackage = Package ( meta_dict . get ( \"datapackage\" )) if not self . datapackage : self . update_datapackage () if self . with_resources : self . resources = [ self . get_resource ( i , source_only = False ) for i in range ( len ( self . datapackage . resources )) ] download () \u00a4 download downloads the dataset Source code in dataherb/core/base.py 234 235 236 237 238 239 def download ( self ): \"\"\" download downloads the dataset \"\"\" raise NotImplementedError ( \"Not implemented\" ) search_score ( keywords , keys = None ) \u00a4 search_score calcualtes the matching score of the herb for any given keyword Parameters: Name Type Description Default keywords Union [ List [ str ], Tuple [ str ], Set [ str ]] keywords for the search required keys Optional [ List [ str ]] list of keys in the dictionary to look into. None Source code in dataherb/core/base.py 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 def search_score ( self , keywords : Union [ List [ str ], Tuple [ str ], Set [ str ]], keys : Optional [ List [ str ]] = None , ) -> float : \"\"\" search_score calcualtes the matching score of the herb for any given keyword :param keywords: keywords for the search :type keywords: list :param keys: list of keys in the dictionary to look into. :type keys: list, optional \"\"\" if keys is None : keys = [ \"name\" , \"id\" , \"repository\" , \"tags\" , \"description\" ] if not isinstance ( keywords , ( list , tuple , set )): keywords = [ keywords ] herb_for_search = { key : val for key , val in self . herb_meta_json . items () if key in keys } herb_for_search = _flatten_dict ( herb_for_search ) keywords_scores = [] for keyword in keywords : for key , val in herb_for_search . items (): score = fuzz . token_set_ratio ( val , keyword ) keywords_scores . append ( score ) max_score = 0 if keywords_scores : max_score = max ( keywords_scores ) return max_score update_datapackage () \u00a4 update_datapackage gets the datapackage metadata from the metadata_uri Source code in dataherb/core/base.py 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 def update_datapackage ( self ) -> None : \"\"\" update_datapackage gets the datapackage metadata from the metadata_uri \"\"\" if self . source == \"git\" : file_content = get_data_from_url ( self . metadata_uri ) if not file_content . status_code == 200 : file_error_msg = \"Could not fetch remote file: {} ; {} \" . format ( self . metadata_uri , file_content . status_code ) click . ClickException ( file_error_msg ) # file_content = json.dumps([{\"url\": self.url, \"error\": file_error_msg}]) else : file_content = file_content . json () # .decode(self.decode) elif self . source == \"s3\" : raise NotImplementedError ( \"Directly get dataherb.json from S3 is not yet implemented.\" ) self . datapackage_meta = file_content self . herb_meta_json [ \"datapackage\" ] = self . datapackage_meta self . datapackage = Package ( self . datapackage_meta ) return self . datapackage","title":"dataherb.core.base"},{"location":"references/core/base/#corebase","text":"","title":"core.base"},{"location":"references/core/base/#dataherb.core.base.Herb","text":"Herb is a collection of the dataset. Parameters: Name Type Description Default meta_dict dict the dictionary that specifies the herb. required base_path Optional [ Path ] the path to the dataset. None with_resources whether to load the resources, i.e., data files. True Source code in dataherb/core/base.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 class Herb : \"\"\" Herb is a collection of the dataset. :param meta_dict: the dictionary that specifies the herb. :param base_path: the path to the dataset. :param with_resources: whether to load the resources, i.e., data files. \"\"\" def __init__ ( self , meta_dict : dict , base_path : Optional [ Path ] = None , with_resources = True ): \"\"\" :param meta_dict: the dictionary that specifies the herb :type meta_dict: dict :param base_path: the path to the dataset :type base_path: pathlib.Path :param with_resources: whether to load the resources, i.e., data files :type with_resources: bool \"\"\" if base_path is None : c = Config () self . base_path = c . workdir else : self . base_path = base_path if isinstance ( self . base_path , str ): self . base_path = Path ( self . base_path ) self . with_resources = with_resources if isinstance ( meta_dict , dict ): self . herb_meta_json = meta_dict elif isinstance ( meta_dict , MetaData ): logger . debug ( \"get herb_meta_json from MetaData ...\" ) self . herb_meta_json = meta_dict . metadata else : logger . debug ( f \"input meta type ( { type ( meta_dict ) } ) is not supported.\" ) click . BadParameter ( f \"input meta type ( { type ( meta_dict ) } ) is not supported.\" , param = meta_dict , ) self . _from_meta_dict ( self . herb_meta_json ) @property def is_local ( self ) -> bool : is_local = False if self . base_path . exists (): is_local = True return is_local def _from_meta_dict ( self , meta_dict : dict ) -> None : \"\"\"Build properties from meta dict\"\"\" self . name = meta_dict . get ( \"name\" ) self . description = meta_dict . get ( \"description\" ) self . repository = meta_dict . get ( \"repository\" ) # Deprecated self . id = meta_dict . get ( \"id\" , \"\" ) self . source = meta_dict . get ( \"source\" ) self . metadata_uri = meta_dict . get ( \"metadata_uri\" , \"\" ) self . uri = meta_dict . get ( \"uri\" ) self . datapackage = Package ( meta_dict . get ( \"datapackage\" )) if not self . datapackage : self . update_datapackage () if self . with_resources : self . resources = [ self . get_resource ( i , source_only = False ) for i in range ( len ( self . datapackage . resources )) ] def get_resource ( self , idx : Optional [ int ] = None , path : Optional [ str ] = None , name : Optional [ str ] = None , source_only : bool = True , ) -> Resource : if idx is None : if path : all_paths = [ r . descriptor . get ( \"path\" ) for r in self . datapackage . resources ] if path in all_paths : idx = all_paths . index ( path ) else : logger . error ( f \"path = { path } is not in resources.\" ) elif name : all_names = [ r . descriptor . get ( \"name\" ) for r in self . datapackage . resources ] if name in all_names : idx = all_names . index ( name ) else : logger . error ( f \"name = { name } is not in resources.\" ) else : raise Exception ( f \"Please specify at least one of the keywords: idx, path, name.\" ) if self . is_local : logger . debug ( f \"Using local dataset for { self . id } , sync it if you need the updated version.\" ) r = self . datapackage . resources [ idx ] logger . debug ( f \"using base_path: { str ( self . base_path ) } \" ) logger . debug ( f \"using descriptor: { r . descriptor } \" ) resource = Resource ( r . descriptor , base_path = str ( self . base_path )) logger . debug ( f \"base_path of r_1: { resource . _Resource__base_path } \" ) elif ( not self . is_local ) and ( self . source == \"git\" ): logger . debug ( f \"Using remote data\" ) self . remote_path = f \" { self . metadata_uri [: - 16 ] } \" r = self . datapackage . resources [ idx ] resource = Resource ( { ** ( r . descriptor ), ** { \"path\" : self . remote_path + r . descriptor . get ( \"path\" , \"\" )}, } ) elif ( not self . is_local ) and ( self . source == \"s3\" ): logger . debug ( f \"Using remote data\" ) logger . debug ( f \"Direct resource from S3 is not supported yet. \" f \"Please sync the dataset to local using the command line first. \\n \" f \"TODO: Sync S3 to local after confirmation from here.\" ) resource = self . datapackage . resources [ idx ] else : logger . error ( \"Resource is not supported. Currently supporting S3 and git.\" ) resource = self . datapackage . resources [ idx ] if source_only : return resource . source else : return resource def update_datapackage ( self ) -> None : \"\"\" update_datapackage gets the datapackage metadata from the metadata_uri \"\"\" if self . source == \"git\" : file_content = get_data_from_url ( self . metadata_uri ) if not file_content . status_code == 200 : file_error_msg = \"Could not fetch remote file: {} ; {} \" . format ( self . metadata_uri , file_content . status_code ) click . ClickException ( file_error_msg ) # file_content = json.dumps([{\"url\": self.url, \"error\": file_error_msg}]) else : file_content = file_content . json () # .decode(self.decode) elif self . source == \"s3\" : raise NotImplementedError ( \"Directly get dataherb.json from S3 is not yet implemented.\" ) self . datapackage_meta = file_content self . herb_meta_json [ \"datapackage\" ] = self . datapackage_meta self . datapackage = Package ( self . datapackage_meta ) return self . datapackage def search_score ( self , keywords : Union [ List [ str ], Tuple [ str ], Set [ str ]], keys : Optional [ List [ str ]] = None , ) -> float : \"\"\" search_score calcualtes the matching score of the herb for any given keyword :param keywords: keywords for the search :type keywords: list :param keys: list of keys in the dictionary to look into. :type keys: list, optional \"\"\" if keys is None : keys = [ \"name\" , \"id\" , \"repository\" , \"tags\" , \"description\" ] if not isinstance ( keywords , ( list , tuple , set )): keywords = [ keywords ] herb_for_search = { key : val for key , val in self . herb_meta_json . items () if key in keys } herb_for_search = _flatten_dict ( herb_for_search ) keywords_scores = [] for keyword in keywords : for key , val in herb_for_search . items (): score = fuzz . token_set_ratio ( val , keyword ) keywords_scores . append ( score ) max_score = 0 if keywords_scores : max_score = max ( keywords_scores ) return max_score @property def metadata ( self ): \"\"\" metadata formats the metadata of the herb \"\"\" return self . herb_meta_json . copy () def download ( self ): \"\"\" download downloads the dataset \"\"\" raise NotImplementedError ( \"Not implemented\" ) # data_files = [] # for leaf_meta in self.herb_meta_json.get(\"data\"): # leaf = Leaf(leaf_meta, self) # data_files.append(leaf.download()) # return data_files def __str__ ( self ): meta = self . metadata authors = meta . get ( \"contributors\" , []) authors = \", \" . join ([ author . get ( \"name\" ) for author in authors ]) return ( f \"DataHerb ID: { meta . get ( 'id' ) } \\n \" f \"name: { meta . get ( 'name' ) } \" f \"description: { meta . get ( 'description' ) } \\n \" f \"contributors: { authors } \" )","title":"Herb"},{"location":"references/core/base/#dataherb.core.base.Herb.metadata","text":"metadata formats the metadata of the herb","title":"metadata"},{"location":"references/core/base/#dataherb.core.base.Herb.__init__","text":"Parameters: Name Type Description Default meta_dict dict the dictionary that specifies the herb required base_path Optional [ Path ] the path to the dataset None with_resources bool whether to load the resources, i.e., data files True Source code in dataherb/core/base.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 def __init__ ( self , meta_dict : dict , base_path : Optional [ Path ] = None , with_resources = True ): \"\"\" :param meta_dict: the dictionary that specifies the herb :type meta_dict: dict :param base_path: the path to the dataset :type base_path: pathlib.Path :param with_resources: whether to load the resources, i.e., data files :type with_resources: bool \"\"\" if base_path is None : c = Config () self . base_path = c . workdir else : self . base_path = base_path if isinstance ( self . base_path , str ): self . base_path = Path ( self . base_path ) self . with_resources = with_resources if isinstance ( meta_dict , dict ): self . herb_meta_json = meta_dict elif isinstance ( meta_dict , MetaData ): logger . debug ( \"get herb_meta_json from MetaData ...\" ) self . herb_meta_json = meta_dict . metadata else : logger . debug ( f \"input meta type ( { type ( meta_dict ) } ) is not supported.\" ) click . BadParameter ( f \"input meta type ( { type ( meta_dict ) } ) is not supported.\" , param = meta_dict , ) self . _from_meta_dict ( self . herb_meta_json )","title":"__init__()"},{"location":"references/core/base/#dataherb.core.base.Herb._from_meta_dict","text":"Build properties from meta dict Source code in dataherb/core/base.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def _from_meta_dict ( self , meta_dict : dict ) -> None : \"\"\"Build properties from meta dict\"\"\" self . name = meta_dict . get ( \"name\" ) self . description = meta_dict . get ( \"description\" ) self . repository = meta_dict . get ( \"repository\" ) # Deprecated self . id = meta_dict . get ( \"id\" , \"\" ) self . source = meta_dict . get ( \"source\" ) self . metadata_uri = meta_dict . get ( \"metadata_uri\" , \"\" ) self . uri = meta_dict . get ( \"uri\" ) self . datapackage = Package ( meta_dict . get ( \"datapackage\" )) if not self . datapackage : self . update_datapackage () if self . with_resources : self . resources = [ self . get_resource ( i , source_only = False ) for i in range ( len ( self . datapackage . resources )) ]","title":"_from_meta_dict()"},{"location":"references/core/base/#dataherb.core.base.Herb.download","text":"download downloads the dataset Source code in dataherb/core/base.py 234 235 236 237 238 239 def download ( self ): \"\"\" download downloads the dataset \"\"\" raise NotImplementedError ( \"Not implemented\" )","title":"download()"},{"location":"references/core/base/#dataherb.core.base.Herb.search_score","text":"search_score calcualtes the matching score of the herb for any given keyword Parameters: Name Type Description Default keywords Union [ List [ str ], Tuple [ str ], Set [ str ]] keywords for the search required keys Optional [ List [ str ]] list of keys in the dictionary to look into. None Source code in dataherb/core/base.py 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 def search_score ( self , keywords : Union [ List [ str ], Tuple [ str ], Set [ str ]], keys : Optional [ List [ str ]] = None , ) -> float : \"\"\" search_score calcualtes the matching score of the herb for any given keyword :param keywords: keywords for the search :type keywords: list :param keys: list of keys in the dictionary to look into. :type keys: list, optional \"\"\" if keys is None : keys = [ \"name\" , \"id\" , \"repository\" , \"tags\" , \"description\" ] if not isinstance ( keywords , ( list , tuple , set )): keywords = [ keywords ] herb_for_search = { key : val for key , val in self . herb_meta_json . items () if key in keys } herb_for_search = _flatten_dict ( herb_for_search ) keywords_scores = [] for keyword in keywords : for key , val in herb_for_search . items (): score = fuzz . token_set_ratio ( val , keyword ) keywords_scores . append ( score ) max_score = 0 if keywords_scores : max_score = max ( keywords_scores ) return max_score","title":"search_score()"},{"location":"references/core/base/#dataherb.core.base.Herb.update_datapackage","text":"update_datapackage gets the datapackage metadata from the metadata_uri Source code in dataherb/core/base.py 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 def update_datapackage ( self ) -> None : \"\"\" update_datapackage gets the datapackage metadata from the metadata_uri \"\"\" if self . source == \"git\" : file_content = get_data_from_url ( self . metadata_uri ) if not file_content . status_code == 200 : file_error_msg = \"Could not fetch remote file: {} ; {} \" . format ( self . metadata_uri , file_content . status_code ) click . ClickException ( file_error_msg ) # file_content = json.dumps([{\"url\": self.url, \"error\": file_error_msg}]) else : file_content = file_content . json () # .decode(self.decode) elif self . source == \"s3\" : raise NotImplementedError ( \"Directly get dataherb.json from S3 is not yet implemented.\" ) self . datapackage_meta = file_content self . herb_meta_json [ \"datapackage\" ] = self . datapackage_meta self . datapackage = Package ( self . datapackage_meta ) return self . datapackage","title":"update_datapackage()"},{"location":"references/core/search/","text":"core.search \u00a4 search_by_ids_in_flora ( flora , ids ) \u00a4 search_in_flora finds the herb with the corresponding ids Parameters: Name Type Description Default flora List [ Herb ] list of herbs required ids Sequence [ str ] ids of the herbs to be located required Returns: Type Description list herbs that matches the id Source code in dataherb/core/search.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 def search_by_ids_in_flora ( flora : List [ Herb ], ids : Sequence [ str ]) -> List [ dict ]: \"\"\" search_in_flora finds the herb with the corresponding ids :param flora: list of herbs :type flora: list :param ids: ids of the herbs to be located :type ids: list :return: herbs that matches the id :rtype: list \"\"\" if not isinstance ( ids , Sequence ): ids = [ ids ] herbs = [] for herb in flora : if herb . id in ids : herb_matched = { \"herb\" : herb , \"id\" : herb . id } herbs . append ( herb_matched ) return herbs search_by_keywords_in_flora ( flora , keywords , keys = None , min_score = 50 ) \u00a4 search_in_flora calculates the match score of each herb and returns the top 10. Parameters: Name Type Description Default flora List [ Herb ] list of herbs required keywords List [ str ] search keywords required keys Optional [ List [ str ]] list of dictionary keys to look into None min_score float minimum score of the dataset, default to 50 50 Source code in dataherb/core/search.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 def search_by_keywords_in_flora ( flora : List [ Herb ], keywords : List [ str ], keys : Optional [ List [ str ]] = None , min_score : float = 50 , ) -> List [ dict ]: \"\"\" search_in_flora calculates the match score of each herb and returns the top 10. :param flora: list of herbs :param keywords: search keywords :param keys: list of dictionary keys to look into :param min_score: minimum score of the dataset, default to 50 \"\"\" if not isinstance ( keywords , List ): keywords = [ keywords ] herb_scores = [] for herb in flora : herb_search_score = { \"id\" : herb . id , \"herb\" : herb , \"score\" : herb . search_score ( keywords ), } herb_scores . append ( herb_search_score ) ranked_herbs = sorted ( herb_scores , key = lambda i : i [ \"score\" ], reverse = True ) ranked_herbs = [ i for i in ranked_herbs if i . get ( \"score\" , 0 ) >= min_score ] return ranked_herbs","title":"dataherb.core.search"},{"location":"references/core/search/#coresearch","text":"","title":"core.search"},{"location":"references/core/search/#dataherb.core.search.search_by_ids_in_flora","text":"search_in_flora finds the herb with the corresponding ids Parameters: Name Type Description Default flora List [ Herb ] list of herbs required ids Sequence [ str ] ids of the herbs to be located required Returns: Type Description list herbs that matches the id Source code in dataherb/core/search.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 def search_by_ids_in_flora ( flora : List [ Herb ], ids : Sequence [ str ]) -> List [ dict ]: \"\"\" search_in_flora finds the herb with the corresponding ids :param flora: list of herbs :type flora: list :param ids: ids of the herbs to be located :type ids: list :return: herbs that matches the id :rtype: list \"\"\" if not isinstance ( ids , Sequence ): ids = [ ids ] herbs = [] for herb in flora : if herb . id in ids : herb_matched = { \"herb\" : herb , \"id\" : herb . id } herbs . append ( herb_matched ) return herbs","title":"search_by_ids_in_flora()"},{"location":"references/core/search/#dataherb.core.search.search_by_keywords_in_flora","text":"search_in_flora calculates the match score of each herb and returns the top 10. Parameters: Name Type Description Default flora List [ Herb ] list of herbs required keywords List [ str ] search keywords required keys Optional [ List [ str ]] list of dictionary keys to look into None min_score float minimum score of the dataset, default to 50 50 Source code in dataherb/core/search.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 def search_by_keywords_in_flora ( flora : List [ Herb ], keywords : List [ str ], keys : Optional [ List [ str ]] = None , min_score : float = 50 , ) -> List [ dict ]: \"\"\" search_in_flora calculates the match score of each herb and returns the top 10. :param flora: list of herbs :param keywords: search keywords :param keys: list of dictionary keys to look into :param min_score: minimum score of the dataset, default to 50 \"\"\" if not isinstance ( keywords , List ): keywords = [ keywords ] herb_scores = [] for herb in flora : herb_search_score = { \"id\" : herb . id , \"herb\" : herb , \"score\" : herb . search_score ( keywords ), } herb_scores . append ( herb_search_score ) ranked_herbs = sorted ( herb_scores , key = lambda i : i [ \"score\" ], reverse = True ) ranked_herbs = [ i for i in ranked_herbs if i . get ( \"score\" , 0 ) >= min_score ] return ranked_herbs","title":"search_by_keywords_in_flora()"},{"location":"references/parse/model_json/","text":"parse.model_json \u00a4 dataherb.parse.model_json is the json based metadata engine. MetaData \u00a4 JSON metadata object Parameters: Name Type Description Default folder Path path to the dataherb folder required Source code in dataherb/parse/model_json.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 class MetaData : \"\"\" JSON metadata object :param folder: path to the dataherb folder \"\"\" def __init__ ( self , folder : Path ): self . dataherb_folder = folder self . metadata_file = \"dataherb.json\" self . metadata : dict = {} def load ( self ) -> dict : \"\"\"load the existing datapackage file\"\"\" metadata_full_path = self . dataherb_folder / self . metadata_file logger . debug ( f \"Load metadata from file: { metadata_full_path } \" ) with open ( metadata_full_path , \"r\" ) as fp : self . metadata = json . load ( fp ) logger . debug ( f \"Loaded metadata: { self . metadata } \" ) return self . metadata def create ( self , overwrite : bool = False ) -> None : \"\"\"creates .dataherb folder\"\"\" try : self . dataherb_folder . mkdir ( parents = True , exist_ok = False ) logger . info ( \"Created \" , self . dataherb_folder ) except FileExistsError : logger . warning ( f \" { self . dataherb_folder } already exists! Will use the folder.\" \"Pass the flag `overwrite=True` to recreate it, if one desires.\" ) metadata_full_path = self . dataherb_folder / self . metadata_file if metadata_full_path . is_file (): if not overwrite : raise FileExistsError ( f \"File { metadata_full_path } already exists!\" ) else : logger . warning ( f \"Will overwrite { metadata_full_path } \" ) with open ( metadata_full_path , \"w\" ) as fp : json . dump ( self . metadata , fp , indent = 4 ) logger . debug ( f \"written to { metadata_full_path } \" ) def validate ( self ) -> None : \"\"\"validate the existing metadata file\"\"\" metadata_full_path = self . dataherb_folder / self . metadata_file self . _validate_paths () with open ( metadata_full_path , \"r\" ) as fp : metadata = json . load ( fp ) logger . info ( \"loaded metadata \" , self . dataherb_folder ) logger . debug ( f \"loaded metadata { metadata } \" ) def _validate_paths ( self ) -> None : \"\"\"Check if the metadata path exists\"\"\" metadata_full_path = self . dataherb_folder / self . metadata_file if not self . dataherb_folder . exists (): raise Exception ( f \"Path { self . dataherb_folder } doesn't exist!\" ) else : logger . info ( f \"Path { self . dataherb_folder } exists.\" ) if not metadata_full_path . is_file (): raise FileNotFoundError ( f \"File { metadata_full_path } doesn't exist!\" ) else : logger . info ( f \"File { metadata_full_path } exists!\" ) _validate_paths () \u00a4 Check if the metadata path exists Source code in dataherb/parse/model_json.py 71 72 73 74 75 76 77 78 79 80 81 82 83 84 def _validate_paths ( self ) -> None : \"\"\"Check if the metadata path exists\"\"\" metadata_full_path = self . dataherb_folder / self . metadata_file if not self . dataherb_folder . exists (): raise Exception ( f \"Path { self . dataherb_folder } doesn't exist!\" ) else : logger . info ( f \"Path { self . dataherb_folder } exists.\" ) if not metadata_full_path . is_file (): raise FileNotFoundError ( f \"File { metadata_full_path } doesn't exist!\" ) else : logger . info ( f \"File { metadata_full_path } exists!\" ) create ( overwrite = False ) \u00a4 creates .dataherb folder Source code in dataherb/parse/model_json.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 def create ( self , overwrite : bool = False ) -> None : \"\"\"creates .dataherb folder\"\"\" try : self . dataherb_folder . mkdir ( parents = True , exist_ok = False ) logger . info ( \"Created \" , self . dataherb_folder ) except FileExistsError : logger . warning ( f \" { self . dataherb_folder } already exists! Will use the folder.\" \"Pass the flag `overwrite=True` to recreate it, if one desires.\" ) metadata_full_path = self . dataherb_folder / self . metadata_file if metadata_full_path . is_file (): if not overwrite : raise FileExistsError ( f \"File { metadata_full_path } already exists!\" ) else : logger . warning ( f \"Will overwrite { metadata_full_path } \" ) with open ( metadata_full_path , \"w\" ) as fp : json . dump ( self . metadata , fp , indent = 4 ) logger . debug ( f \"written to { metadata_full_path } \" ) load () \u00a4 load the existing datapackage file Source code in dataherb/parse/model_json.py 23 24 25 26 27 28 29 30 31 32 def load ( self ) -> dict : \"\"\"load the existing datapackage file\"\"\" metadata_full_path = self . dataherb_folder / self . metadata_file logger . debug ( f \"Load metadata from file: { metadata_full_path } \" ) with open ( metadata_full_path , \"r\" ) as fp : self . metadata = json . load ( fp ) logger . debug ( f \"Loaded metadata: { self . metadata } \" ) return self . metadata validate () \u00a4 validate the existing metadata file Source code in dataherb/parse/model_json.py 59 60 61 62 63 64 65 66 67 68 69 def validate ( self ) -> None : \"\"\"validate the existing metadata file\"\"\" metadata_full_path = self . dataherb_folder / self . metadata_file self . _validate_paths () with open ( metadata_full_path , \"r\" ) as fp : metadata = json . load ( fp ) logger . info ( \"loaded metadata \" , self . dataherb_folder ) logger . debug ( f \"loaded metadata { metadata } \" )","title":"dataherb.parse.model_json"},{"location":"references/parse/model_json/#parsemodel_json","text":"dataherb.parse.model_json is the json based metadata engine.","title":"parse.model_json"},{"location":"references/parse/model_json/#dataherb.parse.model_json.MetaData","text":"JSON metadata object Parameters: Name Type Description Default folder Path path to the dataherb folder required Source code in dataherb/parse/model_json.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 class MetaData : \"\"\" JSON metadata object :param folder: path to the dataherb folder \"\"\" def __init__ ( self , folder : Path ): self . dataherb_folder = folder self . metadata_file = \"dataherb.json\" self . metadata : dict = {} def load ( self ) -> dict : \"\"\"load the existing datapackage file\"\"\" metadata_full_path = self . dataherb_folder / self . metadata_file logger . debug ( f \"Load metadata from file: { metadata_full_path } \" ) with open ( metadata_full_path , \"r\" ) as fp : self . metadata = json . load ( fp ) logger . debug ( f \"Loaded metadata: { self . metadata } \" ) return self . metadata def create ( self , overwrite : bool = False ) -> None : \"\"\"creates .dataherb folder\"\"\" try : self . dataherb_folder . mkdir ( parents = True , exist_ok = False ) logger . info ( \"Created \" , self . dataherb_folder ) except FileExistsError : logger . warning ( f \" { self . dataherb_folder } already exists! Will use the folder.\" \"Pass the flag `overwrite=True` to recreate it, if one desires.\" ) metadata_full_path = self . dataherb_folder / self . metadata_file if metadata_full_path . is_file (): if not overwrite : raise FileExistsError ( f \"File { metadata_full_path } already exists!\" ) else : logger . warning ( f \"Will overwrite { metadata_full_path } \" ) with open ( metadata_full_path , \"w\" ) as fp : json . dump ( self . metadata , fp , indent = 4 ) logger . debug ( f \"written to { metadata_full_path } \" ) def validate ( self ) -> None : \"\"\"validate the existing metadata file\"\"\" metadata_full_path = self . dataherb_folder / self . metadata_file self . _validate_paths () with open ( metadata_full_path , \"r\" ) as fp : metadata = json . load ( fp ) logger . info ( \"loaded metadata \" , self . dataherb_folder ) logger . debug ( f \"loaded metadata { metadata } \" ) def _validate_paths ( self ) -> None : \"\"\"Check if the metadata path exists\"\"\" metadata_full_path = self . dataherb_folder / self . metadata_file if not self . dataherb_folder . exists (): raise Exception ( f \"Path { self . dataherb_folder } doesn't exist!\" ) else : logger . info ( f \"Path { self . dataherb_folder } exists.\" ) if not metadata_full_path . is_file (): raise FileNotFoundError ( f \"File { metadata_full_path } doesn't exist!\" ) else : logger . info ( f \"File { metadata_full_path } exists!\" )","title":"MetaData"},{"location":"references/parse/model_json/#dataherb.parse.model_json.MetaData._validate_paths","text":"Check if the metadata path exists Source code in dataherb/parse/model_json.py 71 72 73 74 75 76 77 78 79 80 81 82 83 84 def _validate_paths ( self ) -> None : \"\"\"Check if the metadata path exists\"\"\" metadata_full_path = self . dataherb_folder / self . metadata_file if not self . dataherb_folder . exists (): raise Exception ( f \"Path { self . dataherb_folder } doesn't exist!\" ) else : logger . info ( f \"Path { self . dataherb_folder } exists.\" ) if not metadata_full_path . is_file (): raise FileNotFoundError ( f \"File { metadata_full_path } doesn't exist!\" ) else : logger . info ( f \"File { metadata_full_path } exists!\" )","title":"_validate_paths()"},{"location":"references/parse/model_json/#dataherb.parse.model_json.MetaData.create","text":"creates .dataherb folder Source code in dataherb/parse/model_json.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 def create ( self , overwrite : bool = False ) -> None : \"\"\"creates .dataherb folder\"\"\" try : self . dataherb_folder . mkdir ( parents = True , exist_ok = False ) logger . info ( \"Created \" , self . dataherb_folder ) except FileExistsError : logger . warning ( f \" { self . dataherb_folder } already exists! Will use the folder.\" \"Pass the flag `overwrite=True` to recreate it, if one desires.\" ) metadata_full_path = self . dataherb_folder / self . metadata_file if metadata_full_path . is_file (): if not overwrite : raise FileExistsError ( f \"File { metadata_full_path } already exists!\" ) else : logger . warning ( f \"Will overwrite { metadata_full_path } \" ) with open ( metadata_full_path , \"w\" ) as fp : json . dump ( self . metadata , fp , indent = 4 ) logger . debug ( f \"written to { metadata_full_path } \" )","title":"create()"},{"location":"references/parse/model_json/#dataherb.parse.model_json.MetaData.load","text":"load the existing datapackage file Source code in dataherb/parse/model_json.py 23 24 25 26 27 28 29 30 31 32 def load ( self ) -> dict : \"\"\"load the existing datapackage file\"\"\" metadata_full_path = self . dataherb_folder / self . metadata_file logger . debug ( f \"Load metadata from file: { metadata_full_path } \" ) with open ( metadata_full_path , \"r\" ) as fp : self . metadata = json . load ( fp ) logger . debug ( f \"Loaded metadata: { self . metadata } \" ) return self . metadata","title":"load()"},{"location":"references/parse/model_json/#dataherb.parse.model_json.MetaData.validate","text":"validate the existing metadata file Source code in dataherb/parse/model_json.py 59 60 61 62 63 64 65 66 67 68 69 def validate ( self ) -> None : \"\"\"validate the existing metadata file\"\"\" metadata_full_path = self . dataherb_folder / self . metadata_file self . _validate_paths () with open ( metadata_full_path , \"r\" ) as fp : metadata = json . load ( fp ) logger . info ( \"loaded metadata \" , self . dataherb_folder ) logger . debug ( f \"loaded metadata { metadata } \" )","title":"validate()"},{"location":"references/utils/awscli/","text":"utils.awscli \u00a4 aws_cli ( cmd ) \u00a4 aws_cli invokes the aws cli processes in python to execute awscli commands. Warning This is not the most elegant way of using awscli. However, it has been a convinient function in data science projects. Examples AWS credential env variables should be configured before calling this function. The awscli command should be wrapped as a tuple. To download data from S3 to a local path, use >>> aws_cli (( 's3' , 'sync' , 's3://s2-fpd/augmentation/' , '/tmp/test' )) Similarly , upload is done in the following way >>> # local_path = '' >>> # remote_path = '' >>> _aws_cli (( 's3' , 'sync' , local_path , remote_path )) References This function is adapted from https://github.com/boto/boto3/issues/358#issuecomment-372086466 Parameters: Name Type Description Default *cmd tuple tuple of awscli command. () Source code in dataherb/utils/awscli.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 def aws_cli ( * cmd ): \"\"\" aws_cli invokes the aws cli processes in python to execute awscli commands. !!! warning This is not the most elegant way of using awscli. However, it has been a convinient function in data science projects. !!! note \"Examples\" AWS credential env variables should be configured before calling this function. The awscli command should be wrapped as a tuple. To download data from S3 to a local path, use ```python >>> aws_cli(('s3', 'sync', 's3://s2-fpd/augmentation/', '/tmp/test')) Similarly, upload is done in the following way >>> # local_path = '' >>> # remote_path = '' >>> _aws_cli(('s3', 'sync', local_path, remote_path)) ``` !!! note \"References\" This function is adapted from https://github.com/boto/boto3/issues/358#issuecomment-372086466 :param tuple *cmd: tuple of awscli command. \"\"\" old_env = dict ( os . environ ) try : # Set up environment env = os . environ . copy () env [ \"LC_CTYPE\" ] = \"en_US.UTF\" os . environ . update ( env ) # Run awscli in the same process exit_code = create_clidriver () . main ( * cmd ) # Deal with problems if exit_code > 0 : raise RuntimeError ( f \"AWS CLI exited with code { exit_code } \" ) finally : os . environ . clear () os . environ . update ( old_env )","title":"dataherb.utils.awscli"},{"location":"references/utils/awscli/#utilsawscli","text":"","title":"utils.awscli"},{"location":"references/utils/awscli/#dataherb.utils.awscli.aws_cli","text":"aws_cli invokes the aws cli processes in python to execute awscli commands. Warning This is not the most elegant way of using awscli. However, it has been a convinient function in data science projects. Examples AWS credential env variables should be configured before calling this function. The awscli command should be wrapped as a tuple. To download data from S3 to a local path, use >>> aws_cli (( 's3' , 'sync' , 's3://s2-fpd/augmentation/' , '/tmp/test' )) Similarly , upload is done in the following way >>> # local_path = '' >>> # remote_path = '' >>> _aws_cli (( 's3' , 'sync' , local_path , remote_path )) References This function is adapted from https://github.com/boto/boto3/issues/358#issuecomment-372086466 Parameters: Name Type Description Default *cmd tuple tuple of awscli command. () Source code in dataherb/utils/awscli.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 def aws_cli ( * cmd ): \"\"\" aws_cli invokes the aws cli processes in python to execute awscli commands. !!! warning This is not the most elegant way of using awscli. However, it has been a convinient function in data science projects. !!! note \"Examples\" AWS credential env variables should be configured before calling this function. The awscli command should be wrapped as a tuple. To download data from S3 to a local path, use ```python >>> aws_cli(('s3', 'sync', 's3://s2-fpd/augmentation/', '/tmp/test')) Similarly, upload is done in the following way >>> # local_path = '' >>> # remote_path = '' >>> _aws_cli(('s3', 'sync', local_path, remote_path)) ``` !!! note \"References\" This function is adapted from https://github.com/boto/boto3/issues/358#issuecomment-372086466 :param tuple *cmd: tuple of awscli command. \"\"\" old_env = dict ( os . environ ) try : # Set up environment env = os . environ . copy () env [ \"LC_CTYPE\" ] = \"en_US.UTF\" os . environ . update ( env ) # Run awscli in the same process exit_code = create_clidriver () . main ( * cmd ) # Deal with problems if exit_code > 0 : raise RuntimeError ( f \"AWS CLI exited with code { exit_code } \" ) finally : os . environ . clear () os . environ . update ( old_env )","title":"aws_cli()"},{"location":"references/utils/data/","text":"utils.data \u00a4 flatten_dict ( nested_dict , sep = None ) \u00a4 flatten_dict flattens a dictionary, The flattened keys are joined using a separater which is default to '__'. Parameters: Name Type Description Default nested_dict dict input nested dictionary to be flattened. required sep str, optional seperator for the joined keys, defaults to __ None Returns: Type Description dict flattened dictionar Source code in dataherb/utils/data.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 def flatten_dict ( nested_dict , sep = None ): \"\"\" flatten_dict flattens a dictionary, The flattened keys are joined using a separater which is default to '__'. :param nested_dict: input nested dictionary to be flattened. :type nested_dict: dict :param sep: seperator for the joined keys, defaults to __ :type sep: str, optional :return: flattened dictionar :rtype: dict \"\"\" if sep is None : sep = \"__\" res = {} def flatten ( x , name = \"\" ): if type ( x ) is dict : for a in x : flatten ( x [ a ], name + a + sep ) elif type ( x ) is list : i = 0 for a in x : flatten ( a , name + str ( i ) + sep ) i += 1 else : res [ name [: - 2 ]] = x flatten ( nested_dict ) return res","title":"dataherb.utils.data"},{"location":"references/utils/data/#utilsdata","text":"","title":"utils.data"},{"location":"references/utils/data/#dataherb.utils.data.flatten_dict","text":"flatten_dict flattens a dictionary, The flattened keys are joined using a separater which is default to '__'. Parameters: Name Type Description Default nested_dict dict input nested dictionary to be flattened. required sep str, optional seperator for the joined keys, defaults to __ None Returns: Type Description dict flattened dictionar Source code in dataherb/utils/data.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 def flatten_dict ( nested_dict , sep = None ): \"\"\" flatten_dict flattens a dictionary, The flattened keys are joined using a separater which is default to '__'. :param nested_dict: input nested dictionary to be flattened. :type nested_dict: dict :param sep: seperator for the joined keys, defaults to __ :type sep: str, optional :return: flattened dictionar :rtype: dict \"\"\" if sep is None : sep = \"__\" res = {} def flatten ( x , name = \"\" ): if type ( x ) is dict : for a in x : flatten ( x [ a ], name + a + sep ) elif type ( x ) is list : i = 0 for a in x : flatten ( a , name + str ( i ) + sep ) i += 1 else : res [ name [: - 2 ]] = x flatten ( nested_dict ) return res","title":"flatten_dict()"},{"location":"tutorials/","text":"Tutorials \u00a4 This is a series of tutorials to help you get started with dataherb . Herbs and Flora \u00a4 The name Dataherb is a metaphor. Each data file is like a Leaf (or Resource ) of a Herb (or Dataset ). Many Herbs form a Flora . Dataherb Term Meaning Herb A Dataset Resource A Data File Leaf and Resource Leaf is an alias of Resource. Managing the Flora \u00a4 This python package ships a command line tool that can be used to manage the Flora . The core of a flora is basically a json file that lists the metadata of herbs. The default flora can be configured using dataherb configure . Using this configuration, we can simply store the json representing the flora and recreate the whole flora on other devices. Sync the Flora to GitHub For example, we can version control the flora and push it to GitHub and pull it down on other devices. In this way, we can sync and restore the flora.","title":"Tutorials"},{"location":"tutorials/#tutorials","text":"This is a series of tutorials to help you get started with dataherb .","title":"Tutorials"},{"location":"tutorials/#herbs-and-flora","text":"The name Dataherb is a metaphor. Each data file is like a Leaf (or Resource ) of a Herb (or Dataset ). Many Herbs form a Flora . Dataherb Term Meaning Herb A Dataset Resource A Data File Leaf and Resource Leaf is an alias of Resource.","title":"Herbs and Flora"},{"location":"tutorials/#managing-the-flora","text":"This python package ships a command line tool that can be used to manage the Flora . The core of a flora is basically a json file that lists the metadata of herbs. The default flora can be configured using dataherb configure . Using this configuration, we can simply store the json representing the flora and recreate the whole flora on other devices. Sync the Flora to GitHub For example, we can version control the flora and push it to GitHub and pull it down on other devices. In this way, we can sync and restore the flora.","title":"Managing the Flora"},{"location":"tutorials/configuration/","text":"Configuration \u00a4 Configuring dataherb is easy. It can be done using the built-in dataherb configure comamnd or manually. Using Command Line Tool \u00a4 Run the command dataherb configure and some questions will show up: [ ? ] Where should I put all the datasets and flora database? An empty folder is recommended.: ~/dataherb [ ? ] How would you name the default flora? Please keep the default value if this is not clear to you.: flora The first question is setting the workdir. Different ways of perserving the metadata We have two different ways of perserving the flora meta data. Using a single file for all the datasets. Using a folder for each dataset. dataherb supports both. By default, we will use folders. For the above configuration, we will find the folder for all the flora metadata at ~/dataherb/flora/flora . Note that ~/[workdir]/flora/ is the path where we put all the flora metadata. If the answer to the second question, aka name of the flora, is set to flora2 , we will have all the flora metadata located at ~/[workdir]/flora/flora 2`. We can have multiple flora, for example, we can have two, flora and flora2 flora \u251c\u2500\u2500 flora \u2502 \u2514\u2500\u2500 git-dataherb-python-demo-dataset \u2502 \u2514\u2500\u2500 dataherb.json \u2514\u2500\u2500 flora2 \u2514\u2500\u2500 git-dataherb-python-demo-dataset-2 \u2514\u2500\u2500 dataherb.json config file already exists If a config file ( ~/.dataherb/config.json ) is already created, a warning will be shown: Config file ( ~/.dataherb/config.json ) already exists You could overwrite it or leave it be. Show Current Configuration \u00a4 To inspect the current configuration, use the option -s (or --show ). dataherb configure -s We will get something similar to the following. The current config for dataherb is: { \"default\" : { \"flora\" : \"flora\" } , \"workdir\" : \"/Users/itsme/dataherb\" } The above config is extracted from ~/.dataherb/config.json Locate the Configuration File \u00a4 The option -l (or --locate ) opens the folder that contains the configuration file config.json . dataherb configure -l Manually Create Configuration \u00a4 Once the dataherb configure command is run, a config.json file will be created inside the folder ~/.dataherb . { \"workdir\" : \"~/dataherb\" , \"default\" : { \"flora\" : \"flora\" , \"aggregrated\" : false } } key example description workdir ~/dataherb The work directory for dataherb. default.flora flora The name of the flora to be used by default. For example, the value flora means we will use the flora.json database in the folder (workdir setting in the above row)/flora/flora.json . default.aggregrated false Whether to use a single json file for all the flora metadata. It is highly recommended to set it to false . More about workdir By default, two folders will be created inside it: ~/dataherb/flora (default storage for all flora) and ~/dataherb/serve (the cache folder for the website of all datasets when we run dataherb serve ) More about default.flora If workdir is set to ~/dataherb , then the database will be ~/dataherb/flora/flora . If the value of default.flora is set to abc , then the database will be ~/dataherb/flora/abc .","title":"Configuration"},{"location":"tutorials/configuration/#configuration","text":"Configuring dataherb is easy. It can be done using the built-in dataherb configure comamnd or manually.","title":"Configuration"},{"location":"tutorials/configuration/#using-command-line-tool","text":"Run the command dataherb configure and some questions will show up: [ ? ] Where should I put all the datasets and flora database? An empty folder is recommended.: ~/dataherb [ ? ] How would you name the default flora? Please keep the default value if this is not clear to you.: flora The first question is setting the workdir. Different ways of perserving the metadata We have two different ways of perserving the flora meta data. Using a single file for all the datasets. Using a folder for each dataset. dataherb supports both. By default, we will use folders. For the above configuration, we will find the folder for all the flora metadata at ~/dataherb/flora/flora . Note that ~/[workdir]/flora/ is the path where we put all the flora metadata. If the answer to the second question, aka name of the flora, is set to flora2 , we will have all the flora metadata located at ~/[workdir]/flora/flora 2`. We can have multiple flora, for example, we can have two, flora and flora2 flora \u251c\u2500\u2500 flora \u2502 \u2514\u2500\u2500 git-dataherb-python-demo-dataset \u2502 \u2514\u2500\u2500 dataherb.json \u2514\u2500\u2500 flora2 \u2514\u2500\u2500 git-dataherb-python-demo-dataset-2 \u2514\u2500\u2500 dataherb.json config file already exists If a config file ( ~/.dataherb/config.json ) is already created, a warning will be shown: Config file ( ~/.dataherb/config.json ) already exists You could overwrite it or leave it be.","title":"Using Command Line Tool"},{"location":"tutorials/configuration/#show-current-configuration","text":"To inspect the current configuration, use the option -s (or --show ). dataherb configure -s We will get something similar to the following. The current config for dataherb is: { \"default\" : { \"flora\" : \"flora\" } , \"workdir\" : \"/Users/itsme/dataherb\" } The above config is extracted from ~/.dataherb/config.json","title":"Show Current Configuration"},{"location":"tutorials/configuration/#locate-the-configuration-file","text":"The option -l (or --locate ) opens the folder that contains the configuration file config.json . dataherb configure -l","title":"Locate the Configuration File"},{"location":"tutorials/configuration/#manually-create-configuration","text":"Once the dataherb configure command is run, a config.json file will be created inside the folder ~/.dataherb . { \"workdir\" : \"~/dataherb\" , \"default\" : { \"flora\" : \"flora\" , \"aggregrated\" : false } } key example description workdir ~/dataherb The work directory for dataherb. default.flora flora The name of the flora to be used by default. For example, the value flora means we will use the flora.json database in the folder (workdir setting in the above row)/flora/flora.json . default.aggregrated false Whether to use a single json file for all the flora metadata. It is highly recommended to set it to false . More about workdir By default, two folders will be created inside it: ~/dataherb/flora (default storage for all flora) and ~/dataherb/serve (the cache folder for the website of all datasets when we run dataherb serve ) More about default.flora If workdir is set to ~/dataherb , then the database will be ~/dataherb/flora/flora . If the value of default.flora is set to abc , then the database will be ~/dataherb/flora/abc .","title":"Manually Create Configuration"},{"location":"tutorials/create/","text":"Create New Dataset \u00a4 The demo dataset We will use the data files in this repository as a demo. Please download the zip of this repo . Create \u00a4 After downloading and unzipping the demo dataset , cd into the folder. In my case, it is cd ~/Downloads/dataherb-python-demo-dataset-main Run the command dataherb create and a few questions will pop out. Your current working directory is /Users/itsme/Downloads/dataherb-python-demo-dataset-main A dataherb.json file will be created right here. Are you sure this is the correct path? [ y/N ] : y This makes sure that we are working in the correct folder. In this case, we type y to confirm. Which Type of Remote \u00a4 [ ? ] Where is/will be the dataset synced to?: git > git s3 Dataherb supports two different types of sources, S3 and git. In this case, we choose git as we would like to sync the dataset to a GitHub repo. Name of the Dataset \u00a4 [ ? ] How would you like to name the dataset?: Dataherb Demo Dataset This will be the name of your dataset. ID of the Dataset \u00a4 [ ? ] Please specify a unique id for the dataset: git-dataherb-python-demo-dataset ID of the dataset has to be unique in your whole flora. Description \u00a4 [ ? ] What is the dataset about? This will be the description of the dataset.: This is a demo dataset to test and show dataherb. Describe the dataset here. URI \u00a4 [ ? ] What is the dataset ' s URI? This will be the URI of the dataset.: https://github.com/DataHerb/dataherb-python-demo-dataset-created.git Result \u00a4 Two things happened after this. A file dataherb.json will be created in the current folder. The metadata for this dataset has been added to the Flora. Content of the dataherb.json file The content of the file should be the following. { \"source\" : \"git\" , \"name\" : \"Dataherb Demo Dataset\" , \"id\" : \"git-dataherb-python-demo-dataset\" , \"description\" : \"This is a demo dataset to test and show dataherb.\" , \"uri\" : \"https://github.com/DataHerb/dataherb-python-demo-dataset-created.git\" , \"metadata_uri\" : \"https://raw.githubusercontent.com/DataHerb/dataherb-python-demo-dataset-created/main/dataherb.json\" , \"datapackage\" : { \"profile\" : \"tabular-data-package\" , \"resources\" : [ { \"path\" : \"dataset/indeed_job_listing.csv\" , \"profile\" : \"tabular-data-resource\" , \"name\" : \"indeed_job_listing\" , \"format\" : \"csv\" , \"mediatype\" : \"text/csv\" , \"encoding\" : \"windows-1252\" , \"schema\" : { \"fields\" : [ { \"name\" : \"title\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"location\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"company\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"description\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"salary\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"url\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"published_at\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"id\" , \"type\" : \"string\" , \"format\" : \"default\" } ], \"missingValues\" : [ \"\" ] } }, { \"path\" : \"dataset/stackoverflow_job_listing.csv\" , \"profile\" : \"tabular-data-resource\" , \"name\" : \"stackoverflow_job_listing\" , \"format\" : \"csv\" , \"mediatype\" : \"text/csv\" , \"encoding\" : \"utf-8\" , \"schema\" : { \"fields\" : [ { \"name\" : \"link\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"category\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"title\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"description\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"published_at\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"location\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"stackoverflow_id\" , \"type\" : \"integer\" , \"format\" : \"default\" }, { \"name\" : \"author\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"location_country\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"location_city\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"updated_at\" , \"type\" : \"string\" , \"format\" : \"default\" } ], \"missingValues\" : [ \"\" ] } } ] } } Sync to Remote \u00a4 WIP Sync local dataset to remote is still a WIP. After creating the dataset, run the command dataherb upload . Using Experimental Feature Use dataherb upload --experimental True to use experimental feature. For example, git repo will automatically add, commit ,and push.","title":"Create Dataset"},{"location":"tutorials/create/#create-new-dataset","text":"The demo dataset We will use the data files in this repository as a demo. Please download the zip of this repo .","title":"Create New Dataset"},{"location":"tutorials/create/#create","text":"After downloading and unzipping the demo dataset , cd into the folder. In my case, it is cd ~/Downloads/dataherb-python-demo-dataset-main Run the command dataherb create and a few questions will pop out. Your current working directory is /Users/itsme/Downloads/dataherb-python-demo-dataset-main A dataherb.json file will be created right here. Are you sure this is the correct path? [ y/N ] : y This makes sure that we are working in the correct folder. In this case, we type y to confirm.","title":"Create"},{"location":"tutorials/create/#which-type-of-remote","text":"[ ? ] Where is/will be the dataset synced to?: git > git s3 Dataherb supports two different types of sources, S3 and git. In this case, we choose git as we would like to sync the dataset to a GitHub repo.","title":"Which Type of Remote"},{"location":"tutorials/create/#name-of-the-dataset","text":"[ ? ] How would you like to name the dataset?: Dataherb Demo Dataset This will be the name of your dataset.","title":"Name of the Dataset"},{"location":"tutorials/create/#id-of-the-dataset","text":"[ ? ] Please specify a unique id for the dataset: git-dataherb-python-demo-dataset ID of the dataset has to be unique in your whole flora.","title":"ID of the Dataset"},{"location":"tutorials/create/#description","text":"[ ? ] What is the dataset about? This will be the description of the dataset.: This is a demo dataset to test and show dataherb. Describe the dataset here.","title":"Description"},{"location":"tutorials/create/#uri","text":"[ ? ] What is the dataset ' s URI? This will be the URI of the dataset.: https://github.com/DataHerb/dataherb-python-demo-dataset-created.git","title":"URI"},{"location":"tutorials/create/#result","text":"Two things happened after this. A file dataherb.json will be created in the current folder. The metadata for this dataset has been added to the Flora. Content of the dataherb.json file The content of the file should be the following. { \"source\" : \"git\" , \"name\" : \"Dataherb Demo Dataset\" , \"id\" : \"git-dataherb-python-demo-dataset\" , \"description\" : \"This is a demo dataset to test and show dataherb.\" , \"uri\" : \"https://github.com/DataHerb/dataherb-python-demo-dataset-created.git\" , \"metadata_uri\" : \"https://raw.githubusercontent.com/DataHerb/dataherb-python-demo-dataset-created/main/dataherb.json\" , \"datapackage\" : { \"profile\" : \"tabular-data-package\" , \"resources\" : [ { \"path\" : \"dataset/indeed_job_listing.csv\" , \"profile\" : \"tabular-data-resource\" , \"name\" : \"indeed_job_listing\" , \"format\" : \"csv\" , \"mediatype\" : \"text/csv\" , \"encoding\" : \"windows-1252\" , \"schema\" : { \"fields\" : [ { \"name\" : \"title\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"location\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"company\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"description\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"salary\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"url\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"published_at\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"id\" , \"type\" : \"string\" , \"format\" : \"default\" } ], \"missingValues\" : [ \"\" ] } }, { \"path\" : \"dataset/stackoverflow_job_listing.csv\" , \"profile\" : \"tabular-data-resource\" , \"name\" : \"stackoverflow_job_listing\" , \"format\" : \"csv\" , \"mediatype\" : \"text/csv\" , \"encoding\" : \"utf-8\" , \"schema\" : { \"fields\" : [ { \"name\" : \"link\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"category\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"title\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"description\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"published_at\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"location\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"stackoverflow_id\" , \"type\" : \"integer\" , \"format\" : \"default\" }, { \"name\" : \"author\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"location_country\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"location_city\" , \"type\" : \"string\" , \"format\" : \"default\" }, { \"name\" : \"updated_at\" , \"type\" : \"string\" , \"format\" : \"default\" } ], \"missingValues\" : [ \"\" ] } } ] } }","title":"Result"},{"location":"tutorials/create/#sync-to-remote","text":"WIP Sync local dataset to remote is still a WIP. After creating the dataset, run the command dataherb upload . Using Experimental Feature Use dataherb upload --experimental True to use experimental feature. For example, git repo will automatically add, commit ,and push.","title":"Sync to Remote"},{"location":"tutorials/download/","text":"Download \u00a4 Download dataset by dataherb id dataherb download git-dataherb-python-demo-dataset The dataset will be downloaded to the workdir set in the configuration step. The folder name will be the dataset id.","title":"Download Dataset"},{"location":"tutorials/download/#download","text":"Download dataset by dataherb id dataherb download git-dataherb-python-demo-dataset The dataset will be downloaded to the workdir set in the configuration step. The folder name will be the dataset id.","title":"Download"},{"location":"tutorials/remove/","text":"Remove Herbs \u00a4 Remove a dataset by the dataherb id dataherb remove git-dataherb-python-demo-dataset The Herb will be removed from the Flora. However, we do not touch files in the actual dataset folder.","title":"Remove Dataset"},{"location":"tutorials/remove/#remove-herbs","text":"Remove a dataset by the dataherb id dataherb remove git-dataherb-python-demo-dataset The Herb will be removed from the Flora. However, we do not touch files in the actual dataset folder.","title":"Remove Herbs"},{"location":"tutorials/search/","text":"Search \u00a4 Search by keyword \u00a4 dataherb search git From the returns, we can find the dataset id which can be used to download the dataset. For example, we find this git-dataherb-python-demo-dataset id as we just added this dataset in the creation step. Search by ID \u00a4 Search by dataherb id dataherb search -i covid19_eu_data See Full Metadata of the Dataset \u00a4 By default, the search result only shows the summary and lists the resources in the dataset. If the full metadata is needed, use the option --full . dataherb search git --full or dataherb search -i covid19_eu_data --full Locate Local Folder of the Dataset \u00a4 Use the flag -l to locate the local folder of the dataset. dataherb search -i covid19_eu_data -l It only works when searching using the id ( -i ).","title":"Search Dataset"},{"location":"tutorials/search/#search","text":"","title":"Search"},{"location":"tutorials/search/#search-by-keyword","text":"dataherb search git From the returns, we can find the dataset id which can be used to download the dataset. For example, we find this git-dataherb-python-demo-dataset id as we just added this dataset in the creation step.","title":"Search by keyword"},{"location":"tutorials/search/#search-by-id","text":"Search by dataherb id dataherb search -i covid19_eu_data","title":"Search by ID"},{"location":"tutorials/search/#see-full-metadata-of-the-dataset","text":"By default, the search result only shows the summary and lists the resources in the dataset. If the full metadata is needed, use the option --full . dataherb search git --full or dataherb search -i covid19_eu_data --full","title":"See Full Metadata of the Dataset"},{"location":"tutorials/search/#locate-local-folder-of-the-dataset","text":"Use the flag -l to locate the local folder of the dataset. dataherb search -i covid19_eu_data -l It only works when searching using the id ( -i ).","title":"Locate Local Folder of the Dataset"},{"location":"tutorials/serve/","text":"Serve \u00a4 WIP Though it works, we are still improving the UI. We can serve the whole flora as a website. To achieve this, simple run dataherb serve This is an example. You can search for datasets using the search box. How Does It Work \u00a4 We are using the material theme of mkdocs in the back to serve the full list of datasets. By default, dataherb will add a folder .serve inside the working directory of dataherb. working directory The working directory is set when using dataherb configure . There the command line will ask for the workdir](../configuration/index.md). To view the current setting of workdir, use the command dataherb configure -s","title":"Serve Flora"},{"location":"tutorials/serve/#serve","text":"WIP Though it works, we are still improving the UI. We can serve the whole flora as a website. To achieve this, simple run dataherb serve This is an example. You can search for datasets using the search box.","title":"Serve"},{"location":"tutorials/serve/#how-does-it-work","text":"We are using the material theme of mkdocs in the back to serve the full list of datasets. By default, dataherb will add a folder .serve inside the working directory of dataherb. working directory The working directory is set when using dataherb configure . There the command line will ask for the workdir](../configuration/index.md). To view the current setting of workdir, use the command dataherb configure -s","title":"How Does It Work"}]}